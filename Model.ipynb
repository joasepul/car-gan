{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, merge, Concatenate, Dense, Dropout, Conv2D, Add, Dot, Lambda, Conv2DTranspose, Dot, Activation, Reshape, BatchNormalization, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Multiply, LeakyReLU, Flatten, MaxPool2D \n",
    "from keras.layers.convolutional import Convolution2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Jose Sepulveda\n",
    "# Description: This is a keras implementation of spectral normalization.\n",
    "#              This was proposed in this paper: https://arxiv.org/pdf/1802.05957.pdf\n",
    "#\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# Stochastic Gradient Descent with Spectral Normalization:\n",
    "#   1) Initialize a random vector u, initialized from an isotropic distribution.\n",
    "#   2) Use the Power iteration method with this vector u on the matrix of wieghts\n",
    "#      to obtain two approximations of eigenvectors.\n",
    "#   3) Calculate the spectral norm of the wieghts matrix.\n",
    "#   4) Update wieghts using vanilla SGD using the spectral norm of the wieghts matrix.\n",
    "\n",
    "def spectral_norm(w):\n",
    "    \"\"\"\n",
    "        Input: tensor of wieghts\n",
    "        Output: SN tensor of wieghts\n",
    "    \"\"\"\n",
    "    def l2_norm(v):\n",
    "        return K.sum(v ** 2) ** 0.5\n",
    "\n",
    "    w_dim = w.shape.as_list()[-1]\n",
    "    # Initialize random vector u\n",
    "    u = K.random_normal(shape=[1, w_dim])\n",
    "\n",
    "    # We need to flatten the wieghts\n",
    "    w_flat = K.reshape(w, [-1, w_dim])\n",
    "\n",
    "    # Power iteration method\n",
    "    v = K.dot(u, K.transpose(w_flat))\n",
    "    v = v / l2_norm(v)\n",
    "    u = K.dot(v, w_flat)\n",
    "    u = u / l2_norm(u)\n",
    "\n",
    "    # Calculate the SN of W\n",
    "    sigma = K.dot(K.dot(v, w_flat), K.transpose(u))\n",
    "    w_sn = w_flat / sigma\n",
    "\n",
    "    # Update wieghts\n",
    "    w_sn = K.reshape(w_sn, w.shape.as_list())\n",
    "    return w_sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlockDown(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "    # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same', strides=2)(input_layer)\n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    #SECOND BLOCK\n",
    "    \n",
    "   \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same')(resblock)\n",
    "     # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Downsample\n",
    "    #resblock = AveragePooling2D()(resblock)\n",
    "    \n",
    "    # Time for the shortcut connection!\n",
    "    \n",
    "    shortcut_identity = Conv2D(channel_size * channel_multiplier, 3, padding='same', strides=2)(input_layer)\n",
    "    #shortcut_identity = AveragePooling2D()(shortcut_identity)\n",
    "    \n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    output_layer = LeakyReLU()(output_layer)\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlockUp(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "    # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2DTranspose(channel_size * channel_multiplier, 3, padding='same', strides=2)(input_layer)\n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    #SECOND BLOCK\n",
    "    \n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2DTranspose(channel_size * channel_multiplier, 3, padding='same')(resblock)\n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Downsample\n",
    "    #resblock = AveragePooling2D()(resblock)\n",
    "    \n",
    "    # Time for the shortcut connection!\n",
    "    \n",
    "    shortcut_identity = Conv2DTranspose(channel_size * channel_multiplier, 1, padding='same', strides=2)(input_layer)\n",
    "    #shortcut_identity = AveragePooling2D()(shortcut_identity)\n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    output_layer = LeakyReLU()(output_layer)\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlock(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "     # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same')(input_layer)\n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock) \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    #SECOND BLOCK   \n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same')(resblock)\n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(input_layer)    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)    \n",
    "    # Time for the shortcut connection!   \n",
    "    shortcut_identity = Conv2D(channel_size * channel_multiplier, 1, padding='same')(input_layer)\n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    output_layer = LeakyReLU()(output_layer)\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def SelfAttentionBlock(input_shape, name=None):\n",
    "    # f = conv\n",
    "    channels = input_shape[-1]\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    f = Conv2D(channels // 8, 1, padding='same')(input_layer)\n",
    "    # f = maxpooling\n",
    "    f = MaxPool2D(pool_size=2, strides=2, padding='same')(f)\n",
    "    \n",
    "    g = Conv2D(channels // 8, 1, padding='same')(input_layer)\n",
    "    \n",
    "    h = Conv2D(channels // 2, 1, padding='same')(input_layer)\n",
    "    h = MaxPool2D(pool_size=2, strides=2, padding='same')(h)\n",
    "    \n",
    "    \n",
    "    g = Reshape((-1, g.shape[-1]))(g)\n",
    "    f = Reshape((-1, g.shape[-1]))(f)\n",
    "    s = Dot(-1)([g, f])\n",
    "    print(\"Shape of s:{}\".format(s.shape))\n",
    "    beta = Activation('softmax')(s)\n",
    "    print(\"Shape of beta:{}\".format(beta.shape))\n",
    "    h = Reshape((-1, h.shape[-1]))(h)\n",
    "    print(\"Shape of h:{}\".format(h.shape))\n",
    "    o = tf.matmul(beta, h)\n",
    "    \n",
    "    gamma = Conv2D(channels, (1, 1), padding='same', use_bias=False, kernel_initializer='he_normal')(input_layer)\n",
    "    #gamma = Reshape((-1, channels // 2))(g)\n",
    "    #print(gamma.shape)\n",
    "    a, x, y ,z = input_layer.shape\n",
    "    print(o.shape)\n",
    "    #o = K.reshape(o, shape=[x,y,z, channels // 2])\n",
    "    o = Reshape((-1,z,channels//2))(o)\n",
    "    o = Conv2D(channels, kernel_size=1, strides=1)(o)\n",
    "  \n",
    "    Wz_yi = gamma * o\n",
    "    output_layer = Add()([Wz_yi, input_layer])\n",
    "    #output_layer = gamma*o + input_layer\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def GlobalSumPooling2D(name=None):\n",
    "    return Lambda(lambda inputs: K.sum(inputs, axis=[1, 2]), name=name)\n",
    "        \n",
    "# Discriminator test\n",
    "def build_discriminator(channel_multiplier=64):\n",
    "    input_shape = (128,128,3)\n",
    "    model_input = Input(shape=input_shape, name=\"D_input\")\n",
    "    resblockdown1 = ResBlockDown(input_shape=input_shape,channel_size=1, channel_multiplier=channel_multiplier, name='D_resblock_down_1')\n",
    "    h = resblockdown1(model_input)\n",
    "#     selfattentionblock = SelfAttentionBlock(input_shape=(64,64,32), name='D_self_attention_block')\n",
    "#     h = selfattentionblock(h)\n",
    "    # Non local block should be here\n",
    "    #print(h.shape)\n",
    "    ch = channel_multiplier\n",
    "    x = input_shape[0]\n",
    "    y = input_shape[1]\n",
    "    resblockdown2 = ResBlockDown(input_shape=(x,y,channel_multiplier),channel_size=2, channel_multiplier=channel_multiplier, name='D_resblock_down_2')\n",
    "    h = resblockdown2(h)\n",
    "    #print(h.shape)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    resblockdown4 = ResBlockDown(input_shape=(x,y,ch),channel_size=4, channel_multiplier=channel_multiplier, name='D_resblock_down_4')\n",
    "    h = resblockdown4(h)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    #print(h.shape)\n",
    "    resblockdown8 = ResBlockDown(input_shape=(x,y,ch),channel_size=8, channel_multiplier=channel_multiplier, name='D_resblock_down_8')\n",
    "    \n",
    "    h = resblockdown8(h)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    \n",
    "\n",
    "    resblockdown16 = ResBlockDown(input_shape=(x,y,ch),channel_size=16, channel_multiplier=channel_multiplier, name='D_resblock_down_16')\n",
    "    h = resblockdown16(h)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    resblock16 = ResBlock(input_shape=(x,y,ch),channel_size=16, channel_multiplier=channel_multiplier, name='D_resblock_16')\n",
    "    h = resblock16(h)\n",
    "\n",
    "    h = Activation('relu', name=\"D_relu\")(h)\n",
    "    h = GlobalAveragePooling2D(name=\"D_global_avg_pooling_2D\")(h)\n",
    "    model_output = Dense(1, name=\"D_dense\")(h)\n",
    "    model_output = LeakyReLU(alpha=0.2)(model_output)\n",
    "    model = Model(model_input, model_output, name=\"Discriminator\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only noise, non conditional\n",
    "def build_generator(channel_multiplier=64):\n",
    "\n",
    "    model_input = Input(shape=(128,), name=\"G_input\")\n",
    "    h = Dense(4*4*16*channel_multiplier, name=\"G_dense\")(model_input)\n",
    "    h = Reshape((4,4,16*channel_multiplier))(h) # 512 = 16*ch\n",
    "    resblockup16 = ResBlockUp(input_shape=(4,4,1024), channel_size=16, channel_multiplier=channel_multiplier, name=\"G_resblock_up_16\")\n",
    "    h = resblockup16(h)\n",
    "    resblockup8 = ResBlockUp(input_shape=(8,8,1024), channel_size=8, channel_multiplier=channel_multiplier, name=\"G_resblock_up_8\")\n",
    "    h = resblockup8(h)\n",
    "    resblockup4 = ResBlockUp(input_shape=(16,16,512), channel_size=4, channel_multiplier=channel_multiplier, name=\"G_resblock_up_4\")\n",
    "    h = resblockup4(h)\n",
    "\n",
    "    resblockup2 = ResBlockUp(input_shape=(64,64,256), channel_size=2, channel_multiplier=channel_multiplier, name=\"G_resblock_up_2\")\n",
    "    h = resblockup2(h)\n",
    "#     need to debug the following\n",
    "    #selfattentionblock = SelfAttentionBlock(input_shape=(64,64,32), name='G_self_attention_block')\n",
    "    #h = selfattentionblock(h)\n",
    "    resblockup1 = ResBlockUp(input_shape=(128,128,128), channel_size=1, channel_multiplier=channel_multiplier, name=\"G_resblock_up_1\")\n",
    "    h = resblockup1(h)\n",
    "    #print(h.shape)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "    model_output = Conv2D(3, kernel_size=3, strides=1, padding='same', activation='tanh')(h)\n",
    "    \n",
    "    return Model(model_input, model_output, name=\"Generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def UNETGenerator(input_img_dim, num_output_channels):\n",
    "    \"\"\"\n",
    "    Creates the generator according to the specs in the paper below.\n",
    "    It's basically a skip layer AutoEncoder\n",
    "    Generator does the following:\n",
    "    1. Takes in an image\n",
    "    2. Generates an image from this image\n",
    "    Differs from a standard GAN because the image isn't random.\n",
    "    This model tries to learn a mapping from a suboptimal image to an optimal image.\n",
    "    [https://arxiv.org/pdf/1611.07004v1.pdf][5. Appendix]\n",
    "    :param input_img_dim: (channel, height, width)\n",
    "    :param output_img_dim: (channel, height, width)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # -------------------------------\n",
    "    # ENCODER\n",
    "    # C64-C128-C256-C512-C512-C512-C512-C512\n",
    "    # 1 layer block = Conv - BN - LeakyRelu\n",
    "    # -------------------------------\n",
    "    stride = 2\n",
    "    merge_mode = 'concat'\n",
    "\n",
    "    # batch norm mode\n",
    "    bn_mode = 2\n",
    "\n",
    "    # batch norm merge axis\n",
    "    bn_axis = 1\n",
    "\n",
    "    input_layer = Input(shape=input_img_dim, name=\"unet_input\")\n",
    "\n",
    "    # 1 encoder C64\n",
    "    # skip batchnorm on this layer on purpose (from paper)\n",
    "    en_1 = Conv2D(64, 4, strides=2, padding=\"same\")(input_layer)\n",
    "    en_1 = LeakyReLU(alpha=0.2)(en_1)\n",
    "    #print(en_1.shape)\n",
    "\n",
    "    # 2 encoder C128\n",
    "    en_2 = Conv2D(128, 4, strides=2,padding='same')(en_1)\n",
    "    en_2 = BatchNormalization()(en_2)\n",
    "    en_2 = LeakyReLU(alpha=0.2)(en_2)\n",
    "    #print(en_2.shape)\n",
    "\n",
    "    # 3 encoder C256\n",
    "    en_3 = Conv2D(256, 4, padding='same', strides=2)(en_2)\n",
    "    en_3 = BatchNormalization()(en_3)\n",
    "    en_3 = LeakyReLU(alpha=0.2)(en_3)\n",
    "    #print(en_3.shape)\n",
    "\n",
    "    # 4 encoder C512\n",
    "    en_4 = Conv2D(512, 4, padding='same', strides=2)(en_3)\n",
    "    en_4 = BatchNormalization()(en_4)\n",
    "    en_4 = LeakyReLU(alpha=0.2)(en_4)\n",
    "   # print(en_4.shape)\n",
    "\n",
    "    # 5 encoder C512\n",
    "    en_5 = Conv2D(512, 4, padding='same', strides=2)(en_4)\n",
    "    en_5 = BatchNormalization()(en_5)\n",
    "    en_5 = LeakyReLU(alpha=0.2)(en_5)\n",
    "    #print(en_5.shape)\n",
    "\n",
    "    # 6 encoder C512\n",
    "    en_6 = Conv2D(512, 4, padding='same', strides=2)(en_5)\n",
    "    en_6 = BatchNormalization()(en_6)\n",
    "    en_6 = LeakyReLU(alpha=0.2)(en_6)\n",
    "   #print(en_6.shape)\n",
    "\n",
    "    # 7 encoder C512\n",
    "    en_7 = Conv2D(512, 4, padding='same', strides=2)(en_6)\n",
    "    en_7 = BatchNormalization()(en_7)\n",
    "    en_7 = LeakyReLU(alpha=0.2)(en_7)\n",
    "    #print(en_7.shape)\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # DECODER\n",
    "    # CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
    "    # 1 layer block = Conv - Upsample - BN - DO - Relu\n",
    "    # also adds skip connections (merge). Takes input from previous layer matching encoder layer\n",
    "    # -------------------------------\n",
    "\n",
    "\n",
    "    # 2 decoder CD1024 (decodes en_7)\n",
    "    de_2 = UpSampling2D(size=(2, 2))(en_7)\n",
    "    de_2 = Conv2D(1024, 4, padding='same')(de_2)\n",
    "    de_2 = BatchNormalization()(de_2)\n",
    "    de_2 = Dropout(rate=0.5)(de_2)\n",
    "    de_2 = Concatenate()([de_2, en_6])\n",
    "    de_2 = Activation('relu')(de_2)\n",
    "\n",
    "    # 3 decoder CD1024 (decodes en_6)\n",
    "    de_3 = UpSampling2D(size=(2, 2))(de_2)\n",
    "    de_3 = Conv2D(1024, 4, padding='same')(de_3)\n",
    "    de_3 = BatchNormalization()(de_3)\n",
    "    de_3 = Dropout(rate=0.5)(de_3)\n",
    "    de_3 = Concatenate()([de_3, en_5])\n",
    "    de_3 = Activation('relu')(de_3)\n",
    "\n",
    "    # 4 decoder CD1024 (decodes en_5)\n",
    "    de_4 = UpSampling2D(size=(2, 2))(de_3)\n",
    "    de_4 = Conv2D(1024, 4, padding='same')(de_4)\n",
    "    de_4 = BatchNormalization()(de_4)\n",
    "    de_4 = Dropout(rate=0.5)(de_4)\n",
    "    de_4 = Concatenate()([de_4, en_4])\n",
    "    de_4 = Activation('relu')(de_4)\n",
    "\n",
    "    # 5 decoder CD1024 (decodes en_4)\n",
    "    de_5 = UpSampling2D(size=(2, 2))(de_4)\n",
    "    de_5 = Conv2D(1024, 4, padding='same')(de_5)\n",
    "    de_5 = BatchNormalization()(de_5)\n",
    "    de_5 = Dropout(rate=0.5)(de_5)\n",
    "    de_5 = Concatenate()([de_5, en_3])\n",
    "    de_5 = Activation('relu')(de_5)\n",
    "\n",
    "    # 6 decoder C512 (decodes en_3)\n",
    "    de_6 = UpSampling2D(size=(2, 2))(de_5)\n",
    "    de_6 = Conv2D(512, 4, padding='same')(de_6)\n",
    "    de_6 = BatchNormalization()(de_6)\n",
    "    de_6 = Dropout(rate=0.5)(de_6)\n",
    "    de_6 = Concatenate()([de_6, en_2])\n",
    "    de_6 = Activation('relu')(de_6)\n",
    "\n",
    "    # 7 decoder CD256 (decodes en_2)\n",
    "    de_7 = UpSampling2D(size=(2, 2))(de_6)\n",
    "    de_7 = Conv2D(256, 4, padding='same')(de_7)\n",
    "    de_7 = BatchNormalization()(de_7)\n",
    "    de_7 = Dropout(rate=0.5)(de_7)\n",
    "    de_7 = Concatenate()([de_7, en_1])\n",
    "    de_7 = Activation('relu')(de_7)\n",
    "\n",
    "    # After the last layer in the decoder, a conv is applied\n",
    "    # to map to the number of output channels (3 in general,\n",
    "    # except in colorization, where it is 2), followed by a Tanh\n",
    "    # function.\n",
    "    de_8 = UpSampling2D(size=(2, 2))(de_7)\n",
    "    de_8 = Conv2D(num_output_channels, 4, padding='same')(de_8)\n",
    "    de_8 = Activation('tanh')(de_8)\n",
    "\n",
    "    unet_generator = Model(input_layer, de_8, name='unet_generator')\n",
    "    return unet_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "def dataLoader(datapath):\n",
    "    edge_filepaths = sorted(glob.glob('./edge-data/'+'edge-1[0-9][0-9][0-9].png')) #sorted(glob.glob(datapath+'edge-*.png'))\n",
    "    img_filepaths = sorted(glob.glob('./edge-data/'+'1[0-9][0-9][0-9].png')) #sorted(glob.glob(datapath+'*.png'))\n",
    "    edges = []\n",
    "    imgs = []\n",
    "    for edge_fp, img_fp in zip(edge_filepaths,img_filepaths):\n",
    "        edge = cv2.imread(edge_fp, 0)\n",
    "        img = cv2.imread(img_fp)\n",
    "        edge[edge != 255] = 0\n",
    "        edge = edge // 255\n",
    "        edge = np.reshape(edge, (edge.shape[0], edge.shape[1], 1))\n",
    "        edges.append(edge)\n",
    "        imgs.append(img)\n",
    "        \n",
    "    return np.array(edges), np.array(imgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, imgs = dataLoader('./edge-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers \n",
    "import keras.backend as K\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    " \n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.local_variables_initializer())\n",
    "# Create a session with the above options specified.\n",
    "K.tensorflow_backend.set_session(sess)\n",
    "###################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperperemeter\n",
    "BATCHSIZE=9\n",
    "LEARNING_RATE = 0.01\n",
    "TRAINING_RATIO = 1\n",
    "BETA_1 = 0.0\n",
    "BETA_2 = 0.9\n",
    "EPOCHS = 500\n",
    "BN_MIMENTUM = 0.9\n",
    "BN_EPSILON  = 0.00002\n",
    "SAVE_DIR = 'gen-imgs/'\n",
    "\n",
    "GENERATE_ROW_NUM = 3\n",
    "GENERATE_BATCHSIZE = GENERATE_ROW_NUM*GENERATE_ROW_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs/255*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jose\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#DISCRIMINATOR MODEL\n",
    "optimizer = Adam(0.004, 0.5)\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jose\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Adversarial model\n",
    "discriminator.trainable = False\n",
    "optimizer = Adam(0.001, 0.5)\n",
    "input_edge = Input(shape=(128,128,1))\n",
    "unet_generator = UNETGenerator((128,128,1),3)\n",
    "generated_image = unet_generator(input_edge)\n",
    "discriminator_output = discriminator(generated_image)\n",
    "adversarial_net = Model(input_edge, discriminator_output)\n",
    "adversarial_net.compile(loss='mse', optimizer=optimizer)\n",
    "discriminator.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_img(img_list, epoch):\n",
    "    for i, img in enumerate(img_list):\n",
    "        if i!=0:\n",
    "            fig = np.concatenate((fig,(img + 1)/2),axis=1)\n",
    "        else:\n",
    "            fig = (img + 1)/2\n",
    "    print('plot generated_image')\n",
    "    plt.imsave('gen-imgs/epoch_{}.png'.format(epoch), fig)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0/111 [..............................] - ETA: 0sWARNING:tensorflow:From C:\\Users\\Jose\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jose\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/111 [============================>.] - ETA: 2s\n",
      "D (loss_r,acc_r):[5.613988, 0.0] (loss_f,acc_f):[0.7352437, 0.11111111]\n",
      "A loss:3.0188140869140625\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[1.5014836, 0.0] (loss_f,acc_f):[0.18512242, 0.8888889]\n",
      "A loss:0.06804441660642624\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.54624194, 0.5555556] (loss_f,acc_f):[0.049874917, 1.0]\n",
      "A loss:1.8530927896499634\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[6.367742, 0.0] (loss_f,acc_f):[0.18655871, 0.8888889]\n",
      "A loss:1.7118315696716309\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[1.506273, 0.0] (loss_f,acc_f):[0.021252088, 1.0]\n",
      "A loss:1.2762846946716309\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.24113975, 0.7777778] (loss_f,acc_f):[0.273415, 0.44444445]\n",
      "A loss:0.21134844422340393\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.3104078, 0.8888889] (loss_f,acc_f):[0.008478191, 1.0]\n",
      "A loss:1.1337872743606567\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.57038075, 0.11111111] (loss_f,acc_f):[0.015069296, 1.0]\n",
      "A loss:0.4192080497741699\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.14710978, 0.8888889] (loss_f,acc_f):[0.036687482, 1.0]\n",
      "A loss:0.5176575779914856\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.50762707, 0.44444445] (loss_f,acc_f):[0.027568452, 1.0]\n",
      "A loss:0.5097154378890991\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.024043776, 1.0] (loss_f,acc_f):[0.038946994, 1.0]\n",
      "A loss:0.6347664594650269\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.108162686, 1.0] (loss_f,acc_f):[0.10228601, 0.8888889]\n",
      "A loss:0.49169790744781494\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.15101089, 0.8888889] (loss_f,acc_f):[0.042355377, 1.0]\n",
      "A loss:0.774250328540802\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.017797165, 1.0] (loss_f,acc_f):[0.039148387, 1.0]\n",
      "A loss:0.6494923233985901\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[1.0557815, 0.0] (loss_f,acc_f):[0.0019741075, 1.0]\n",
      "A loss:0.8816050887107849\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.009903504, 1.0] (loss_f,acc_f):[0.012337098, 1.0]\n",
      "A loss:0.7476256489753723\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.16148932, 0.8888889] (loss_f,acc_f):[0.016843377, 1.0]\n",
      "A loss:0.4856671690940857\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.091439135, 1.0] (loss_f,acc_f):[0.067016914, 1.0]\n",
      "A loss:0.8125878572463989\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.02641215, 1.0] (loss_f,acc_f):[0.038686775, 1.0]\n",
      "A loss:0.7189863324165344\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[0.008659952, 1.0] (loss_f,acc_f):[0.04706697, 1.0]\n",
      "A loss:0.5118385553359985\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[259598360000000.0, 0.0] (loss_f,acc_f):[153025150000000.0, 0.0]\n",
      "A loss:139533194625024.0\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[32315065000000.0, 0.0] (loss_f,acc_f):[232167500000.0, 0.0]\n",
      "A loss:219744043008.0\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[27073303000000.0, 0.0] (loss_f,acc_f):[177243700000.0, 0.0]\n",
      "A loss:150769434624.0\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[7259832700000.0, 0.0] (loss_f,acc_f):[280396070000.0, 0.0]\n",
      "A loss:188803907584.0\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[24109092000000.0, 0.0] (loss_f,acc_f):[91272480000.0, 0.0]\n",
      "A loss:84200038400.0\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[3516559000000.0, 0.0] (loss_f,acc_f):[129991330000.0, 0.0]\n",
      "A loss:99761700864.0\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[8328498000000.0, 0.0] (loss_f,acc_f):[45598040000.0, 0.0]\n",
      "A loss:38858211328.0\n",
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 1s\n",
      "D (loss_r,acc_r):[3960909000000.0, 0.0] (loss_f,acc_f):[36601700000.0, 0.0]\n",
      "A loss:30632304640.0\n",
      "plot generated_image\n",
      " 49/111 [============>.................] - ETA: 1:56"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    s = np.arange(imgs.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    X = imgs[s]\n",
    "    Y = edges[s]\n",
    "\n",
    "\n",
    "    #print(\"epoch {} of {}\".format(epoch+1, EPOCHS))\n",
    "    num_batches = int(X.shape[0] // BATCHSIZE)\n",
    "    #print(\"number of batches: {}\".format(int(X.shape[0] // (BATCHSIZE))))\n",
    "    progress_bar = Progbar(target=int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO)))\n",
    "    minibatches_size = BATCHSIZE * TRAINING_RATIO\n",
    "    start_time = time()\n",
    "    \n",
    "    for index in range(int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO))):\n",
    "        progress_bar.update(index)\n",
    "        indices = np.arange(X.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        indices = indices[:BATCHSIZE]\n",
    "        images_real = X[indices]\n",
    "        edges_batch = Y[indices]\n",
    "        #print(edges_batch.shape)\n",
    "        labels_real = np.ones([BATCHSIZE,1], dtype=np.float32)\n",
    "        labels_fake = np.zeros([BATCHSIZE,1], dtype=np.float32)\n",
    "        \n",
    "        images_fake = unet_generator.predict(edges_batch)\n",
    "        #train_batch = np.concatenate((image_batch, images_fake))\n",
    "        d_loss_r = discriminator.train_on_batch(images_real, labels_real)\n",
    "        d_loss_f = discriminator.train_on_batch(images_fake, labels_fake)\n",
    "        \n",
    "        #discriminator.trainable = False\n",
    "        a_loss_1 = adversarial_net.train_on_batch(edges_batch, labels_real)\n",
    "        #a_loss_2 = adversarial_net.train_on_batch(edges_batch, y)\n",
    "        #discriminator.trainable = True\n",
    "    print()\n",
    "    print(\"D (loss_r,acc_r):{0} (loss_f,acc_f):{1}\".format(d_loss_r, d_loss_f))\n",
    "    print(\"A loss:{0}\".format(a_loss_1))\n",
    "\n",
    "    gen_imgs = unet_generator.predict(edges_batch)\n",
    "    save_img(images_fake, epoch)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
