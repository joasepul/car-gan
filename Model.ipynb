{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, Add, Dot, Lambda, Conv2DTranspose, Dot, Activation, Reshape, BatchNormalization, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Multiply, LeakyReLU, Flatten, MaxPool2D \n",
    "from keras.models import Model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Jose Sepulveda\n",
    "# Description: This is a keras implementation of spectral normalization.\n",
    "#              This was proposed in this paper: https://arxiv.org/pdf/1802.05957.pdf\n",
    "#\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# Stochastic Gradient Descent with Spectral Normalization:\n",
    "#   1) Initialize a random vector u, initialized from an isotropic distribution.\n",
    "#   2) Use the Power iteration method with this vector u on the matrix of wieghts\n",
    "#      to obtain two approximations of eigenvectors.\n",
    "#   3) Calculate the spectral norm of the wieghts matrix.\n",
    "#   4) Update wieghts using vanilla SGD using the spectral norm of the wieghts matrix.\n",
    "\n",
    "def spectral_norm(w):\n",
    "    \"\"\"\n",
    "        Input: tensor of wieghts\n",
    "        Output: SN tensor of wieghts\n",
    "    \"\"\"\n",
    "    def l2_norm(v):\n",
    "        return K.sum(v ** 2) ** 0.5\n",
    "\n",
    "    w_dim = w.shape.as_list()[-1]\n",
    "    # Initialize random vector u\n",
    "    u = K.random_normal(shape=[1, w_dim])\n",
    "\n",
    "    # We need to flatten the wieghts\n",
    "    w_flat = K.reshape(w, [-1, w_dim])\n",
    "\n",
    "    # Power iteration method\n",
    "    v = K.dot(u, K.transpose(w_flat))\n",
    "    v = v / l2_norm(v)\n",
    "    u = K.dot(v, w_flat)\n",
    "    u = u / l2_norm(u)\n",
    "\n",
    "    # Calculate the SN of W\n",
    "    sigma = K.dot(K.dot(v, w_flat), K.transpose(u))\n",
    "    w_sn = w_flat / sigma\n",
    "\n",
    "    # Update wieghts\n",
    "    w_sn = K.reshape(w_sn, w.shape.as_list())\n",
    "    return w_sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlockDown(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "    # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(input_layer)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same', strides=2, kernel_regularizer=spectral_norm)(resblock)\n",
    "    #SECOND BLOCK\n",
    "    \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same', kernel_regularizer=spectral_norm)(resblock)\n",
    "    # Downsample\n",
    "    #resblock = AveragePooling2D()(resblock)\n",
    "    \n",
    "    # Time for the shortcut connection!\n",
    "    \n",
    "    shortcut_identity = Conv2D(channel_size * channel_multiplier, 3, padding='same', strides=2, kernel_regularizer=spectral_norm)(input_layer)\n",
    "    #shortcut_identity = AveragePooling2D()(shortcut_identity)\n",
    "    \n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlockUp(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "    # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(input_layer)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2DTranspose(channel_size * channel_multiplier, 3, padding='same', strides=2, kernel_regularizer=spectral_norm)(resblock)\n",
    "    \n",
    "    #SECOND BLOCK\n",
    "    \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2DTranspose(channel_size * channel_multiplier, 3, padding='same', kernel_regularizer=spectral_norm)(resblock)\n",
    "    \n",
    "    # Downsample\n",
    "    #resblock = AveragePooling2D()(resblock)\n",
    "    \n",
    "    # Time for the shortcut connection!\n",
    "    \n",
    "    shortcut_identity = Conv2DTranspose(channel_size * channel_multiplier, 1, padding='same', strides=2, kernel_regularizer=spectral_norm)(input_layer)\n",
    "    #shortcut_identity = AveragePooling2D()(shortcut_identity)\n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlock(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "     # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(input_layer)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same', kernel_regularizer=spectral_norm)(resblock)\n",
    "    \n",
    "    #SECOND BLOCK\n",
    "    \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(input_layer)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same', kernel_regularizer=spectral_norm)(resblock)\n",
    "    \n",
    "    \n",
    "    # Time for the shortcut connection!\n",
    "    \n",
    "    shortcut_identity = Conv2D(channel_size * channel_multiplier, 1, padding='same', kernel_regularizer=spectral_norm)(input_layer)\n",
    "    \n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def SelfAttentionBlock(input_shape, name=None):\n",
    "    # f = conv\n",
    "    channels = input_shape[-1]\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    f = Conv2D(channels // 8, 1, padding='same')(input_layer)\n",
    "    # f = maxpooling\n",
    "    f = MaxPool2D(pool_size=2, strides=2, padding='same')(f)\n",
    "    \n",
    "    g = Conv2D(channels // 8, 1, padding='same')(input_layer)\n",
    "    \n",
    "    h = Conv2D(channels // 2, 1, padding='same')(input_layer)\n",
    "    h = MaxPool2D(pool_size=2, strides=2, padding='same')(h)\n",
    "    \n",
    "    \n",
    "    g = Lambda(lambda input1: K.reshape(input1, shape=[-1,1]))(g)\n",
    "    f = Lambda(lambda input1: K.reshape(input1, shape=[-1,1]))(f)\n",
    "    s = Dot(-1)([g, f])\n",
    "    beta = Activation('softmax')(s)\n",
    "\n",
    "    h = Lambda(lambda input1: K.reshape(input1, shape=[-1,1]))(h)\n",
    "    o = Dot(-1)([beta, h])\n",
    "    \n",
    "    gamma = Conv2D(channels, (1, 1), padding='same', use_bias=False, kernel_initializer='he_normal')(input_layer)\n",
    "    #gamma = Reshape((-1, channels // 2))(g)\n",
    "    #print(gamma.shape)\n",
    "    a, x, y ,z = input_layer.shape\n",
    "    #o = K.reshape(o, shape=[x,y,z, channels // 2])\n",
    "    o = Lambda(lambda input1: K.reshape(input1, shape=[x,y,z, channels // 2]))(o)\n",
    "    o = Conv2D(channels, kernel_size=1, strides=1)(o)\n",
    "  \n",
    "    Wz_yi = Multiply()([gamma, o])\n",
    "    output_layer = Add()([Wz_yi, input_layer])\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "    # g = conv\n",
    "    # h = conv\n",
    "    # h = maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "D_input (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "D_resblock_down_1 (Model)    (None, 64, 64, 64)        40780     \n",
      "_________________________________________________________________\n",
      "D_self_attention_block (Mode (64, 64, 64, 64)          9328      \n",
      "_________________________________________________________________\n",
      "D_resblock_down_2 (Model)    multiple                  296064    \n",
      "_________________________________________________________________\n",
      "D_resblock_down_4 (Model)    multiple                  1181952   \n",
      "_________________________________________________________________\n",
      "D_resblock_down_8 (Model)    multiple                  4723200   \n",
      "_________________________________________________________________\n",
      "D_resblock_down_16 (Model)   multiple                  18883584  \n",
      "_________________________________________________________________\n",
      "D_resblock_16 (Model)        multiple                  10491904  \n",
      "_________________________________________________________________\n",
      "D_relu (Activation)          (64, 4, 4, 1024)          0         \n",
      "_________________________________________________________________\n",
      "D_global_sum_pooling_2D (Lam (64, 1024)                0         \n",
      "_________________________________________________________________\n",
      "D_dense (Dense)              (64, 1)                   1025      \n",
      "=================================================================\n",
      "Total params: 35,627,837\n",
      "Trainable params: 35,619,895\n",
      "Non-trainable params: 7,942\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def GlobalSumPooling2D(name=None):\n",
    "    return Lambda(lambda inputs: K.sum(inputs, axis=[1, 2]), name=name)\n",
    "        \n",
    "# Discriminator test\n",
    "def build_discriminator(channel_multiplier=64):\n",
    "    model_input = Input(shape=(128,128,3), name=\"D_input\")\n",
    "    resblockdown1 = ResBlockDown(input_shape=(128,128,3),channel_size=1, channel_multiplier=channel_multiplier, name='D_resblock_down_1')\n",
    "    h = resblockdown1(model_input)\n",
    "    selfattentionblock = SelfAttentionBlock(input_shape=(64,64,64), name='D_self_attention_block')\n",
    "    h = selfattentionblock(h)\n",
    "    # Non local block should be here\n",
    "    resblockdown2 = ResBlockDown(input_shape=(64,64,64),channel_size=2, channel_multiplier=channel_multiplier, name='D_resblock_down_2')\n",
    "    h = resblockdown2(h)\n",
    "    resblockdown4 = ResBlockDown(input_shape=(32,32,128),channel_size=4, channel_multiplier=channel_multiplier, name='D_resblock_down_4')\n",
    "    h = resblockdown4(h)\n",
    "    resblockdown8 = ResBlockDown(input_shape=(16,16,256),channel_size=8, channel_multiplier=channel_multiplier, name='D_resblock_down_8')\n",
    "    h = resblockdown8(h)\n",
    "    resblockdown16 = ResBlockDown(input_shape=(8,8,512),channel_size=16, channel_multiplier=channel_multiplier, name='D_resblock_down_16')\n",
    "    h = resblockdown16(h)\n",
    "    resblock16 = ResBlock(input_shape=(4,4,1024),channel_size=16, channel_multiplier=channel_multiplier, name='D_resblock_16')\n",
    "    h = resblock16(h)\n",
    "    h = Activation('relu', name=\"D_relu\")(h)\n",
    "    h = GlobalSumPooling2D(name=\"D_global_sum_pooling_2D\")(h)\n",
    "    model_output = Dense(1, name=\"D_dense\")(h)\n",
    "    model = Model(model_input, model_output, name=\"Discriminator\")\n",
    "    return model\n",
    "build_discriminator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only noise, non conditional\n",
    "def build_generator(channel_multiplier=64):\n",
    "    model_input = Input(shape=(128,), name=\"G_input\")\n",
    "    h = Dense(4*4*16*channel_multiplier, name=\"G_dense\")(model_input)\n",
    "    h = Reshape((4,4,16*channel_multiplier))(h)\n",
    "    resblockup16 = ResBlockUp(input_shape=(4,4,1024), channel_size=16, channel_multiplier=channel_multiplier, name=\"G_resblock_up_16\")\n",
    "    h = resblockup16(h)\n",
    "    resblockup8 = ResBlockUp(input_shape=(8,8,1024), channel_size=8, channel_multiplier=channel_multiplier, name=\"G_resblock_up_8\")\n",
    "    h = resblockup8(h)\n",
    "    resblockup4 = ResBlockUp(input_shape=(16,16,512), channel_size=4, channel_multiplier=channel_multiplier, name=\"G_resblock_up_4\")\n",
    "    h = resblockup4(h)\n",
    "    resblockup2 = ResBlockUp(input_shape=(32,32,256), channel_size=2, channel_multiplier=channel_multiplier, name=\"G_resblock_up_2\")\n",
    "    h = resblockup2(h)\n",
    "#     need to debug the following\n",
    "#     selfattentionblock = SelfAttentionBlock(input_shape=(64,64,128), name='G_self_attention_block')\n",
    "#     h = selfattentionblock(h)\n",
    "    resblockup1 = ResBlockUp(input_shape=(64,64,128), channel_size=1, channel_multiplier=channel_multiplier, name=\"G_resblock_up_1\")\n",
    "    h = resblockup1(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "    model_output = model_output\n",
    "    \n",
    "    return Model(model_input, model_output, name=\"Generator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "G_input (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "G_dense (Dense)              (None, 16384)             2113536   \n",
      "_________________________________________________________________\n",
      "reshape_18 (Reshape)         (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "G_resblock_up_16 (Model)     (None, 8, 8, 1024)        19934208  \n",
      "_________________________________________________________________\n",
      "G_resblock_up_8 (Model)      (None, 16, 16, 512)       7609856   \n",
      "_________________________________________________________________\n",
      "G_resblock_up_4 (Model)      (None, 32, 32, 256)       1904384   \n",
      "_________________________________________________________________\n",
      "G_resblock_up_2 (Model)      (None, 64, 64, 128)       477056    \n",
      "_________________________________________________________________\n",
      "G_resblock_up_1 (Model)      (None, 128, 128, 64)      119744    \n",
      "=================================================================\n",
      "Total params: 32,158,784\n",
      "Trainable params: 32,148,928\n",
      "Non-trainable params: 9,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_generator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
