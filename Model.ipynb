{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, Add, Dot, Lambda, Conv2DTranspose, Dot, Activation, Reshape, BatchNormalization, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Multiply, LeakyReLU, Flatten, MaxPool2D \n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Jose Sepulveda\n",
    "# Description: This is a keras implementation of spectral normalization.\n",
    "#              This was proposed in this paper: https://arxiv.org/pdf/1802.05957.pdf\n",
    "#\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# Stochastic Gradient Descent with Spectral Normalization:\n",
    "#   1) Initialize a random vector u, initialized from an isotropic distribution.\n",
    "#   2) Use the Power iteration method with this vector u on the matrix of wieghts\n",
    "#      to obtain two approximations of eigenvectors.\n",
    "#   3) Calculate the spectral norm of the wieghts matrix.\n",
    "#   4) Update wieghts using vanilla SGD using the spectral norm of the wieghts matrix.\n",
    "\n",
    "def spectral_norm(w):\n",
    "    \"\"\"\n",
    "        Input: tensor of wieghts\n",
    "        Output: SN tensor of wieghts\n",
    "    \"\"\"\n",
    "    def l2_norm(v):\n",
    "        return K.sum(v ** 2) ** 0.5\n",
    "\n",
    "    w_dim = w.shape.as_list()[-1]\n",
    "    # Initialize random vector u\n",
    "    u = K.random_normal(shape=[1, w_dim])\n",
    "\n",
    "    # We need to flatten the wieghts\n",
    "    w_flat = K.reshape(w, [-1, w_dim])\n",
    "\n",
    "    # Power iteration method\n",
    "    v = K.dot(u, K.transpose(w_flat))\n",
    "    v = v / l2_norm(v)\n",
    "    u = K.dot(v, w_flat)\n",
    "    u = u / l2_norm(u)\n",
    "\n",
    "    # Calculate the SN of W\n",
    "    sigma = K.dot(K.dot(v, w_flat), K.transpose(u))\n",
    "    w_sn = w_flat / sigma\n",
    "\n",
    "    # Update wieghts\n",
    "    w_sn = K.reshape(w_sn, w.shape.as_list())\n",
    "    return w_sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlockDown(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "    # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(input_layer)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same', strides=2)(resblock)\n",
    "    #SECOND BLOCK\n",
    "    \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same')(resblock)\n",
    "    # Downsample\n",
    "    #resblock = AveragePooling2D()(resblock)\n",
    "    \n",
    "    # Time for the shortcut connection!\n",
    "    \n",
    "    shortcut_identity = Conv2D(channel_size * channel_multiplier, 3, padding='same', strides=2)(input_layer)\n",
    "    #shortcut_identity = AveragePooling2D()(shortcut_identity)\n",
    "    \n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlockUp(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "    # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(input_layer)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2DTranspose(channel_size * channel_multiplier, 3, padding='same', strides=2)(resblock)\n",
    "    \n",
    "    #SECOND BLOCK\n",
    "    \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2DTranspose(channel_size * channel_multiplier, 3, padding='same')(resblock)\n",
    "    \n",
    "    # Downsample\n",
    "    #resblock = AveragePooling2D()(resblock)\n",
    "    \n",
    "    # Time for the shortcut connection!\n",
    "    \n",
    "    shortcut_identity = Conv2DTranspose(channel_size * channel_multiplier, 1, padding='same', strides=2)(input_layer)\n",
    "    #shortcut_identity = AveragePooling2D()(shortcut_identity)\n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlock(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "     # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(input_layer) \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same')(resblock)\n",
    "    \n",
    "    #SECOND BLOCK   \n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(input_layer)    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same')(resblock)\n",
    "     \n",
    "    # Time for the shortcut connection!   \n",
    "    shortcut_identity = Conv2D(channel_size * channel_multiplier, 1, padding='same')(input_layer)\n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def SelfAttentionBlock(input_shape, name=None):\n",
    "    # f = conv\n",
    "    channels = input_shape[-1]\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    f = Conv2D(channels // 8, 1, padding='same')(input_layer)\n",
    "    # f = maxpooling\n",
    "    f = MaxPool2D(pool_size=2, strides=2, padding='same')(f)\n",
    "    \n",
    "    g = Conv2D(channels // 8, 1, padding='same')(input_layer)\n",
    "    \n",
    "    h = Conv2D(channels // 2, 1, padding='same')(input_layer)\n",
    "    h = MaxPool2D(pool_size=2, strides=2, padding='same')(h)\n",
    "    \n",
    "    \n",
    "    g = Reshape((-1, g.shape[-1]))(g)\n",
    "    f = Reshape((-1, g.shape[-1]))(f)\n",
    "    s = Dot(-1)([g, f])\n",
    "    print(\"Shape of s:{}\".format(s.shape))\n",
    "    beta = Activation('softmax')(s)\n",
    "    print(\"Shape of beta:{}\".format(beta.shape))\n",
    "    h = Reshape((-1, h.shape[-1]))(h)\n",
    "    print(\"Shape of h:{}\".format(h.shape))\n",
    "    o = tf.matmul(beta, h)\n",
    "    \n",
    "    gamma = Conv2D(channels, (1, 1), padding='same', use_bias=False, kernel_initializer='he_normal')(input_layer)\n",
    "    #gamma = Reshape((-1, channels // 2))(g)\n",
    "    #print(gamma.shape)\n",
    "    a, x, y ,z = input_layer.shape\n",
    "    print(o.shape)\n",
    "    #o = K.reshape(o, shape=[x,y,z, channels // 2])\n",
    "    o = Reshape((-1,z,channels//2))(o)\n",
    "    o = Conv2D(channels, kernel_size=1, strides=1)(o)\n",
    "  \n",
    "    Wz_yi = gamma * o\n",
    "    output_layer = Add()([Wz_yi, input_layer])\n",
    "    #output_layer = gamma*o + input_layer\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of s:(?, ?, ?)\n",
      "Shape of beta:(?, ?, ?)\n",
      "Shape of h:(?, ?, 16)\n",
      "(?, ?, 16)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 64 and 32 for 'mul_1' (op: 'Mul') with input shapes: [?,64,64,32], [?,?,32,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1658\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1659\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1660\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 64 and 32 for 'mul_1' (op: 'Mul') with input shapes: [?,64,64,32], [?,?,32,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-98259c048831>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mbuild_discriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-98259c048831>\u001b[0m in \u001b[0;36mbuild_discriminator\u001b[1;34m(channel_multiplier)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mresblockdown1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResBlockDown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchannel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_multiplier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchannel_multiplier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'D_resblock_down_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresblockdown1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mselfattentionblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelfAttentionBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'D_self_attention_block'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselfattentionblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Non local block should be here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-6468be04b36c>\u001b[0m in \u001b[0;36mSelfAttentionBlock\u001b[1;34m(input_shape, name)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mWz_yi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0moutput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWz_yi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m#output_layer = gamma*o + input_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1076\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1079\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6174\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6175\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 6176\u001b[1;33m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   6177\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6178\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    789\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3300\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1823\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1660\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1662\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 64 and 32 for 'mul_1' (op: 'Mul') with input shapes: [?,64,64,32], [?,?,32,32]."
     ]
    }
   ],
   "source": [
    "\n",
    "def GlobalSumPooling2D(name=None):\n",
    "    return Lambda(lambda inputs: K.sum(inputs, axis=[1, 2]), name=name)\n",
    "        \n",
    "# Discriminator test\n",
    "def build_discriminator(channel_multiplier=64):\n",
    "    input_shape = (128,128,3)\n",
    "    model_input = Input(shape=input_shape, name=\"D_input\")\n",
    "    resblockdown1 = ResBlockDown(input_shape=input_shape,channel_size=1, channel_multiplier=channel_multiplier, name='D_resblock_down_1')\n",
    "    h = resblockdown1(model_input)\n",
    "    selfattentionblock = SelfAttentionBlock(input_shape=(64,64,32), name='D_self_attention_block')\n",
    "    h = selfattentionblock(h)\n",
    "    # Non local block should be here\n",
    "    #print(h.shape)\n",
    "    ch = channel_multiplier\n",
    "    x = input_shape[0]\n",
    "    y = input_shape[1]\n",
    "    resblockdown2 = ResBlockDown(input_shape=(x,y,channel_multiplier),channel_size=2, channel_multiplier=channel_multiplier, name='D_resblock_down_2')\n",
    "    h = resblockdown2(h)\n",
    "    #print(h.shape)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    resblockdown4 = ResBlockDown(input_shape=(x,y,ch),channel_size=4, channel_multiplier=channel_multiplier, name='D_resblock_down_4')\n",
    "    h = resblockdown4(h)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    #print(h.shape)\n",
    "    resblockdown8 = ResBlockDown(input_shape=(x,y,ch),channel_size=8, channel_multiplier=channel_multiplier, name='D_resblock_down_8')\n",
    "    \n",
    "    h = resblockdown8(h)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    \n",
    "\n",
    "    resblockdown16 = ResBlockDown(input_shape=(x,y,ch),channel_size=16, channel_multiplier=channel_multiplier, name='D_resblock_down_16')\n",
    "    h = resblockdown16(h)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    resblock16 = ResBlock(input_shape=(x,y,ch),channel_size=16, channel_multiplier=channel_multiplier, name='D_resblock_16')\n",
    "    h = resblock16(h)\n",
    "\n",
    "    h = Activation('relu', name=\"D_relu\")(h)\n",
    "    h = GlobalSumPooling2D(name=\"D_global_sum_pooling_2D\")(h)\n",
    "    model_output = Dense(1, name=\"D_dense\")(h)\n",
    "    model = Model(model_input, model_output, name=\"Discriminator\")\n",
    "    return model\n",
    "\n",
    "build_discriminator().summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "G_input (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "G_dense (Dense)              (None, 16384)             2113536   \n",
      "_________________________________________________________________\n",
      "reshape_26 (Reshape)         (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "G_resblock_up_16 (Model)     (None, 8, 8, 1024)        19934208  \n",
      "_________________________________________________________________\n",
      "G_resblock_up_8 (Model)      (None, 16, 16, 512)       7609856   \n",
      "_________________________________________________________________\n",
      "G_resblock_up_4 (Model)      (None, 32, 32, 256)       1904384   \n",
      "_________________________________________________________________\n",
      "G_resblock_up_2 (Model)      multiple                  477056    \n",
      "_________________________________________________________________\n",
      "G_resblock_up_1 (Model)      multiple                  119744    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "=================================================================\n",
      "Total params: 32,160,771\n",
      "Trainable params: 32,150,787\n",
      "Non-trainable params: 9,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# only noise, non conditional\n",
    "def build_generator(channel_multiplier=64):\n",
    "\n",
    "    model_input = Input(shape=(128,), name=\"G_input\")\n",
    "    h = Dense(4*4*16*channel_multiplier, name=\"G_dense\")(model_input)\n",
    "    h = Reshape((4,4,16*channel_multiplier))(h) # 512 = 16*ch\n",
    "    resblockup16 = ResBlockUp(input_shape=(4,4,1024), channel_size=16, channel_multiplier=channel_multiplier, name=\"G_resblock_up_16\")\n",
    "    h = resblockup16(h)\n",
    "    resblockup8 = ResBlockUp(input_shape=(8,8,1024), channel_size=8, channel_multiplier=channel_multiplier, name=\"G_resblock_up_8\")\n",
    "    h = resblockup8(h)\n",
    "    resblockup4 = ResBlockUp(input_shape=(16,16,512), channel_size=4, channel_multiplier=channel_multiplier, name=\"G_resblock_up_4\")\n",
    "    h = resblockup4(h)\n",
    "\n",
    "    resblockup2 = ResBlockUp(input_shape=(64,64,256), channel_size=2, channel_multiplier=channel_multiplier, name=\"G_resblock_up_2\")\n",
    "    h = resblockup2(h)\n",
    "#     need to debug the following\n",
    "    #selfattentionblock = SelfAttentionBlock(input_shape=(64,64,32), name='G_self_attention_block')\n",
    "    #h = selfattentionblock(h)\n",
    "    resblockup1 = ResBlockUp(input_shape=(128,128,128), channel_size=1, channel_multiplier=channel_multiplier, name=\"G_resblock_up_1\")\n",
    "    h = resblockup1(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "    model_output = Conv2D(3, kernel_size=3, strides=1, padding='same', activation='tanh')(h)\n",
    "    \n",
    "    return Model(model_input, model_output, name=\"Generator\")\n",
    "build_generator().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_u_net_generator(channel_multiplier=64):\n",
    "\n",
    "    model_input = Input(shape=(128,), name=\"G_input\")\n",
    "    h = Dense(4*4*16*channel_multiplier, name=\"G_dense\")(model_input)\n",
    "    h = Reshape((4,4,16*channel_multiplier))(h) # 512 = 16*ch\n",
    "    resblockup16 = ResBlockUp(input_shape=(4,4,1024), channel_size=16, channel_multiplier=channel_multiplier, name=\"G_resblock_up_16\")\n",
    "    h = resblockup16(h)\n",
    "    resblockup8 = ResBlockUp(input_shape=(8,8,1024), channel_size=8, channel_multiplier=channel_multiplier, name=\"G_resblock_up_8\")\n",
    "    h = resblockup8(h)\n",
    "    resblockup4 = ResBlockUp(input_shape=(16,16,512), channel_size=4, channel_multiplier=channel_multiplier, name=\"G_resblock_up_4\")\n",
    "    h = resblockup4(h)\n",
    "\n",
    "    resblockup2 = ResBlockUp(input_shape=(64,64,256), channel_size=2, channel_multiplier=channel_multiplier, name=\"G_resblock_up_2\")\n",
    "    h = resblockup2(h)\n",
    "#     need to debug the following\n",
    "    #selfattentionblock = SelfAttentionBlock(input_shape=(64,64,32), name='G_self_attention_block')\n",
    "    #h = selfattentionblock(h)\n",
    "    resblockup1 = ResBlockUp(input_shape=(128,128,128), channel_size=1, channel_multiplier=channel_multiplier, name=\"G_resblock_up_1\")\n",
    "    h = resblockup1(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "    model_output = Conv2D(3, kernel_size=3, strides=1, padding='same', activation='tanh')(h)\n",
    "    \n",
    "    return Model(model_input, model_output, name=\"Generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "def dataLoader(datapath):\n",
    "    edge_filepaths = sorted(glob.glob(datapath+'edge-*.png'))\n",
    "    img_filepaths = sorted(glob.glob(datapath+'*.png'))\n",
    "    edges = []\n",
    "    imgs = []\n",
    "    for edge_fp, img_fp in zip(edge_filepaths,img_filepaths):\n",
    "        edge = cv2.imread(edge_fp, 0)\n",
    "        img = cv2.imread(img_fp)\n",
    "        edge[edge != 255] = 0\n",
    "        edge = edge // 255\n",
    "        edges.append(edge)\n",
    "        imgs.append(img)\n",
    "        \n",
    "    return np.array(edges), np.array(imgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8144, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "edges, imgs = dataLoader('./edge-data/')\n",
    "print(edges.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(edges[346])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers \n",
    "import keras.backend as K\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    " \n",
    "# Create a session with the above options specified.\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "###################################\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperperemeter\n",
    "BATCHSIZE=16\n",
    "LEARNING_RATE = 0.0002\n",
    "TRAINING_RATIO = 1\n",
    "BETA_1 = 0.0\n",
    "BETA_2 = 0.9\n",
    "EPOCHS = 500\n",
    "BN_MIMENTUM = 0.9\n",
    "BN_EPSILON  = 0.00002\n",
    "SAVE_DIR = 'gen-imgs/'\n",
    "\n",
    "GENERATE_ROW_NUM = 4\n",
    "GENERATE_BATCHSIZE = GENERATE_ROW_NUM*GENERATE_ROW_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jose\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "model_for_training_generator\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Generator (Model)            (None, 128, 128, 3)       32160771  \n",
      "_________________________________________________________________\n",
      "Discriminator (Model)        (None, 1)                 35618509  \n",
      "=================================================================\n",
      "Total params: 67,779,280\n",
      "Trainable params: 32,150,787\n",
      "Non-trainable params: 35,628,493\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "Noise_input_for_training_generator = Input(shape=(128,))\n",
    "Generated_image                    = generator(Noise_input_for_training_generator)\n",
    "Discriminator_output               = discriminator(Generated_image)\n",
    "model_for_training_generator       = Model(Noise_input_for_training_generator, Discriminator_output)\n",
    "print(\"model_for_training_generator\")\n",
    "discriminator.trainable = False\n",
    "model_for_training_generator.summary()\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_for_training_generator.compile(optimizer=Adam(LEARNING_RATE, beta_1=BETA_1, beta_2=BETA_2), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_for_training_discriminator\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Generator (Model)               (None, 128, 128, 3)  32160771    input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Discriminator (Model)           (None, 1)            35618509    input_13[0][0]                   \n",
      "                                                                 Generator[2][0]                  \n",
      "==================================================================================================\n",
      "Total params: 67,779,280\n",
      "Trainable params: 35,610,567\n",
      "Non-trainable params: 32,168,713\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Real_image                             = Input(shape=(128,128,3))\n",
    "Noise_input_for_training_discriminator = Input(shape=(128,))\n",
    "Fake_image                             = generator(Noise_input_for_training_discriminator)\n",
    "Discriminator_output_for_real          = discriminator(Real_image)\n",
    "Discriminator_output_for_fake          = discriminator(Fake_image)\n",
    "\n",
    "model_for_training_discriminator       = Model([Real_image,\n",
    "                                                Noise_input_for_training_discriminator],\n",
    "                                               [Discriminator_output_for_real,\n",
    "                                                Discriminator_output_for_fake])\n",
    "print(\"model_for_training_discriminator\")\n",
    "generator.trainable = False\n",
    "discriminator.trainable = True\n",
    "model_for_training_discriminator.compile(optimizer=Adam(LEARNING_RATE/1.5, beta_1=BETA_1, beta_2=BETA_2), loss=['mean_squared_error','mean_squared_error'])\n",
    "model_for_training_discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_y = np.ones((BATCHSIZE, 1), dtype=np.float32)\n",
    "fake_y = -real_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imgs/255*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 of 500\n",
      "number of batches: 509\n",
      "  0/509 [..............................] - ETA: 0sWARNING:tensorflow:From C:\\Users\\Jose\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 246.57747316360474\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 2 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 233.60049271583557\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 3 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 232.94044256210327\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 4 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 232.50178146362305\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 5 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 232.58337020874023\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "plot generated_image\n",
      "epoch 6 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 231.77925729751587\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "plot generated_image\n",
      "epoch 7 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 232.64038610458374\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 8 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 232.1392776966095\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 9 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 232.41406154632568\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 10 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 232.36429047584534\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 11 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 233.31128239631653\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 12 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 233.00932812690735\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 13 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 233.01953434944153\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 14 of 500\n",
      "number of batches: 509\n",
      "508/509 [============================>.] - ETA: 0s\n",
      "epoch time: 232.9928584098816\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "plot generated_image\n",
      "epoch 15 of 500\n",
      "number of batches: 509\n",
      "  0/509 [..............................] - ETA: 0s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-45ee99d6ee69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mgenerator_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_for_training_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCHSIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nepoch time: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "test_noise = np.random.randn(GENERATE_BATCHSIZE, 128)\n",
    "W_loss = []\n",
    "discriminator_loss = []\n",
    "generator_loss = []\n",
    "for epoch in range(EPOCHS):\n",
    "    np.random.shuffle(X)\n",
    "    \n",
    "    print(\"epoch {} of {}\".format(epoch+1, EPOCHS))\n",
    "    num_batches = int(X.shape[0] // BATCHSIZE)\n",
    "    \n",
    "    print(\"number of batches: {}\".format(int(X.shape[0] // (BATCHSIZE))))\n",
    "    \n",
    "    progress_bar = Progbar(target=int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO)))\n",
    "    minibatches_size = BATCHSIZE * TRAINING_RATIO\n",
    "    \n",
    "    start_time = time()\n",
    "    for index in range(int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO))):\n",
    "        progress_bar.update(index)\n",
    "        discriminator_minibatches = X[index * minibatches_size:(index + 1) * minibatches_size]\n",
    "        \n",
    "        for j in range(TRAINING_RATIO):\n",
    "            image_batch = discriminator_minibatches[j * BATCHSIZE : (j + 1) * BATCHSIZE]\n",
    "            noise = np.random.randn(BATCHSIZE, 128).astype(np.float32)\n",
    "            discriminator.trainable = True\n",
    "            generator.trainable = False\n",
    "            discriminator_loss.append(model_for_training_discriminator.train_on_batch([image_batch, noise],\n",
    "                                                                                      [real_y, fake_y]))\n",
    "        discriminator.trainable = False\n",
    "        generator.trainable = True\n",
    "        generator_loss.append(model_for_training_generator.train_on_batch(np.random.randn(BATCHSIZE, 128), real_y))\n",
    "    \n",
    "    print('\\nepoch time: {}'.format(time()-start_time))\n",
    "    \n",
    "    W_real = model_for_training_generator.evaluate(test_noise, real_y)\n",
    "    #print(W_real)\n",
    "    W_fake = model_for_training_generator.evaluate(test_noise, fake_y)\n",
    "    #print(W_fake)\n",
    "    W_l = W_real+W_fake\n",
    "    #print('wasserstein_loss: {}'.format(W_l))\n",
    "    W_loss.append(W_l)\n",
    "    #Generate image\n",
    "    generated_image = generator.predict(test_noise)\n",
    "    generated_image = (generated_image+1)/2\n",
    "    for i in range(GENERATE_ROW_NUM):\n",
    "        new = generated_image[i*GENERATE_ROW_NUM:i*GENERATE_ROW_NUM+GENERATE_ROW_NUM].reshape(128*GENERATE_ROW_NUM,128,3)\n",
    "        if i!=0:\n",
    "            old = np.concatenate((old,new),axis=1)\n",
    "        else:\n",
    "            old = new\n",
    "    print('plot generated_image')\n",
    "    plt.imsave('{}/epoch_{}.png'.format(SAVE_DIR, epoch), old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_img = generator.predict(test_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_img = (gen_img +1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.8568259 , 0.77873147, 0.7490115 ],\n",
       "         [0.85222054, 0.7882384 , 0.8131676 ],\n",
       "         [0.846822  , 0.7554947 , 0.54355377],\n",
       "         ...,\n",
       "         [0.92997754, 0.88324034, 0.92553425],\n",
       "         [0.9221339 , 0.8859236 , 0.8709059 ],\n",
       "         [0.8447546 , 0.8508223 , 0.86675775]],\n",
       "\n",
       "        [[0.77683294, 0.71496195, 0.79499555],\n",
       "         [0.6143031 , 0.76517934, 0.73243475],\n",
       "         [0.9018154 , 0.8817203 , 0.8182306 ],\n",
       "         ...,\n",
       "         [0.9754667 , 0.97314394, 0.98516893],\n",
       "         [0.9705703 , 0.9692347 , 0.968985  ],\n",
       "         [0.92441714, 0.8927977 , 0.8763908 ]],\n",
       "\n",
       "        [[0.667995  , 0.793537  , 0.8577317 ],\n",
       "         [0.84004986, 0.86460924, 0.8482611 ],\n",
       "         [0.66421014, 0.6898828 , 0.79323053],\n",
       "         ...,\n",
       "         [0.97276604, 0.9887979 , 0.99215627],\n",
       "         [0.9405527 , 0.9679005 , 0.97065294],\n",
       "         [0.94424367, 0.9637456 , 0.9563525 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.39122728, 0.3916723 , 0.3942794 ],\n",
       "         [0.27499598, 0.3531556 , 0.32414132],\n",
       "         [0.34435928, 0.35780483, 0.3840445 ],\n",
       "         ...,\n",
       "         [0.02650273, 0.05030692, 0.05755624],\n",
       "         [0.08978257, 0.09830737, 0.08808899],\n",
       "         [0.08586127, 0.05833188, 0.18313721]],\n",
       "\n",
       "        [[0.3172868 , 0.3709362 , 0.40012768],\n",
       "         [0.26150337, 0.31577057, 0.37752894],\n",
       "         [0.31990612, 0.382932  , 0.40363687],\n",
       "         ...,\n",
       "         [0.08181331, 0.12293574, 0.21191749],\n",
       "         [0.17595926, 0.08213675, 0.10299075],\n",
       "         [0.13296452, 0.09450734, 0.10558254]],\n",
       "\n",
       "        [[0.4028321 , 0.38607645, 0.42593387],\n",
       "         [0.31478786, 0.389711  , 0.35303143],\n",
       "         [0.25517422, 0.35970742, 0.3551951 ],\n",
       "         ...,\n",
       "         [0.03641647, 0.04784787, 0.06900188],\n",
       "         [0.07087421, 0.06348103, 0.08835441],\n",
       "         [0.11852294, 0.13468853, 0.15520784]]],\n",
       "\n",
       "\n",
       "       [[[0.97934234, 0.9642459 , 0.9180639 ],\n",
       "         [0.98939466, 0.9723376 , 0.9631218 ],\n",
       "         [0.9901459 , 0.96930987, 0.85847163],\n",
       "         ...,\n",
       "         [0.98620796, 0.9756013 , 0.9891702 ],\n",
       "         [0.9824345 , 0.9619525 , 0.9498265 ],\n",
       "         [0.93408126, 0.93654674, 0.9447832 ]],\n",
       "\n",
       "        [[0.98307973, 0.9597095 , 0.9872023 ],\n",
       "         [0.97422606, 0.9925907 , 0.98397946],\n",
       "         [0.9986044 , 0.997753  , 0.9947125 ],\n",
       "         ...,\n",
       "         [0.9985279 , 0.9987494 , 0.99909896],\n",
       "         [0.9971589 , 0.99744207, 0.99737084],\n",
       "         [0.9794641 , 0.97739255, 0.9777521 ]],\n",
       "\n",
       "        [[0.9766128 , 0.99290323, 0.9968076 ],\n",
       "         [0.99883765, 0.99946433, 0.9993319 ],\n",
       "         [0.9734673 , 0.9868946 , 0.99219954],\n",
       "         ...,\n",
       "         [0.9991524 , 0.99983954, 0.99983704],\n",
       "         [0.997732  , 0.99921024, 0.9991833 ],\n",
       "         [0.992619  , 0.9970937 , 0.9961625 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.40776026, 0.42979506, 0.43681198],\n",
       "         [0.32747978, 0.37933785, 0.43500024],\n",
       "         [0.3483538 , 0.40022016, 0.3444835 ],\n",
       "         ...,\n",
       "         [0.27214643, 0.3293907 , 0.32580554],\n",
       "         [0.297732  , 0.3366034 , 0.37767643],\n",
       "         [0.3268692 , 0.34880853, 0.36834913]],\n",
       "\n",
       "        [[0.41471487, 0.46790108, 0.49043503],\n",
       "         [0.39161468, 0.46038896, 0.48840332],\n",
       "         [0.37892497, 0.47375408, 0.4552926 ],\n",
       "         ...,\n",
       "         [0.24708533, 0.3036895 , 0.3353765 ],\n",
       "         [0.26194257, 0.28907096, 0.28967822],\n",
       "         [0.27432734, 0.2999733 , 0.26631495]],\n",
       "\n",
       "        [[0.4828073 , 0.46698308, 0.5071412 ],\n",
       "         [0.48802197, 0.56891334, 0.51180124],\n",
       "         [0.3666889 , 0.45345294, 0.44795644],\n",
       "         ...,\n",
       "         [0.25351965, 0.31910706, 0.28456342],\n",
       "         [0.19665468, 0.24549538, 0.2928652 ],\n",
       "         [0.29789054, 0.31750324, 0.37066156]]],\n",
       "\n",
       "\n",
       "       [[[0.94589573, 0.9171493 , 0.8707132 ],\n",
       "         [0.96248746, 0.920627  , 0.92313564],\n",
       "         [0.9655712 , 0.91040254, 0.7328408 ],\n",
       "         ...,\n",
       "         [0.9865072 , 0.97521436, 0.9888147 ],\n",
       "         [0.9834995 , 0.9610108 , 0.94852716],\n",
       "         [0.9321046 , 0.93550575, 0.9444183 ]],\n",
       "\n",
       "        [[0.94268334, 0.88840103, 0.9474473 ],\n",
       "         [0.9103562 , 0.9657784 , 0.94188344],\n",
       "         [0.98964775, 0.98550415, 0.97101784],\n",
       "         ...,\n",
       "         [0.998512  , 0.99861586, 0.99903977],\n",
       "         [0.9973894 , 0.99738604, 0.9973302 ],\n",
       "         [0.9793079 , 0.974508  , 0.97531724]],\n",
       "\n",
       "        [[0.8816297 , 0.94729304, 0.97259283],\n",
       "         [0.9795587 , 0.9876236 , 0.98519903],\n",
       "         [0.8567188 , 0.891909  , 0.9383208 ],\n",
       "         ...,\n",
       "         [0.99907553, 0.9998004 , 0.99980617],\n",
       "         [0.9974942 , 0.99909574, 0.9990777 ],\n",
       "         [0.9917215 , 0.99659634, 0.99553084]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.39240637, 0.40305072, 0.40556613],\n",
       "         [0.29805416, 0.3594948 , 0.39037797],\n",
       "         [0.33730397, 0.3839636 , 0.34087497],\n",
       "         ...,\n",
       "         [0.21396512, 0.27138746, 0.258718  ],\n",
       "         [0.2580694 , 0.29215735, 0.30115962],\n",
       "         [0.32703635, 0.29856557, 0.31700122]],\n",
       "\n",
       "        [[0.36302215, 0.41134363, 0.43940747],\n",
       "         [0.33297977, 0.39981914, 0.41983598],\n",
       "         [0.32980806, 0.42484   , 0.41715878],\n",
       "         ...,\n",
       "         [0.21291032, 0.2697364 , 0.26661494],\n",
       "         [0.2411837 , 0.24482358, 0.24020523],\n",
       "         [0.26300365, 0.2784642 , 0.22956234]],\n",
       "\n",
       "        [[0.43860742, 0.42397687, 0.46470302],\n",
       "         [0.41723233, 0.5042526 , 0.44131994],\n",
       "         [0.30998707, 0.4062318 , 0.40001458],\n",
       "         ...,\n",
       "         [0.23178512, 0.29144058, 0.29359102],\n",
       "         [0.18161973, 0.21585831, 0.27642804],\n",
       "         [0.29872495, 0.32611942, 0.3530785 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.97617185, 0.95758826, 0.92052674],\n",
       "         [0.98721635, 0.96545947, 0.9558791 ],\n",
       "         [0.98876274, 0.9610647 , 0.8200035 ],\n",
       "         ...,\n",
       "         [0.9856498 , 0.97315884, 0.988883  ],\n",
       "         [0.98377264, 0.9606925 , 0.94974077],\n",
       "         [0.94190145, 0.944718  , 0.95103395]],\n",
       "\n",
       "        [[0.98334324, 0.95634437, 0.98703384],\n",
       "         [0.9719419 , 0.99101496, 0.9828917 ],\n",
       "         [0.9987533 , 0.9980549 , 0.99585277],\n",
       "         ...,\n",
       "         [0.9987512 , 0.99891573, 0.999089  ],\n",
       "         [0.9979321 , 0.9981758 , 0.998155  ],\n",
       "         [0.9821379 , 0.98107535, 0.97984684]],\n",
       "\n",
       "        [[0.97179586, 0.99170184, 0.99659294],\n",
       "         [0.9987302 , 0.99946487, 0.9993377 ],\n",
       "         [0.97388375, 0.9865079 , 0.9921341 ],\n",
       "         ...,\n",
       "         [0.99955684, 0.9999197 , 0.9999015 ],\n",
       "         [0.9988209 , 0.9995954 , 0.9995549 ],\n",
       "         [0.9945515 , 0.99812603, 0.9975196 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3543595 , 0.35247883, 0.36098495],\n",
       "         [0.21490684, 0.2859788 , 0.26725304],\n",
       "         [0.25829357, 0.26314908, 0.21797216],\n",
       "         ...,\n",
       "         [0.10622975, 0.16943419, 0.12685141],\n",
       "         [0.14241827, 0.16039044, 0.16074315],\n",
       "         [0.2248767 , 0.20110264, 0.2519077 ]],\n",
       "\n",
       "        [[0.31825387, 0.36668658, 0.37684608],\n",
       "         [0.2797483 , 0.32378364, 0.33043545],\n",
       "         [0.2528757 , 0.31238592, 0.28412947],\n",
       "         ...,\n",
       "         [0.10595164, 0.14607891, 0.14831796],\n",
       "         [0.16749033, 0.16416514, 0.12999108],\n",
       "         [0.17265424, 0.18005368, 0.14199206]],\n",
       "\n",
       "        [[0.4283399 , 0.39449018, 0.44090477],\n",
       "         [0.3742242 , 0.42983404, 0.37885743],\n",
       "         [0.22261387, 0.30496648, 0.29164028],\n",
       "         ...,\n",
       "         [0.14125544, 0.17824939, 0.14574605],\n",
       "         [0.11469677, 0.13955745, 0.16551775],\n",
       "         [0.22046909, 0.22524756, 0.28060758]]],\n",
       "\n",
       "\n",
       "       [[[0.76309425, 0.6904571 , 0.6629727 ],\n",
       "         [0.79174864, 0.73811054, 0.79868084],\n",
       "         [0.7993036 , 0.7216201 , 0.5441911 ],\n",
       "         ...,\n",
       "         [0.93621176, 0.89176977, 0.9306043 ],\n",
       "         [0.9242023 , 0.8923118 , 0.8781309 ],\n",
       "         [0.8480807 , 0.8485551 , 0.86405396]],\n",
       "\n",
       "        [[0.7037741 , 0.6697798 , 0.7393051 ],\n",
       "         [0.59524447, 0.7217094 , 0.70313364],\n",
       "         [0.87494344, 0.84646916, 0.78277314],\n",
       "         ...,\n",
       "         [0.975412  , 0.9742569 , 0.98576117],\n",
       "         [0.9715518 , 0.9719075 , 0.9713248 ],\n",
       "         [0.93084604, 0.9037199 , 0.8829622 ]],\n",
       "\n",
       "        [[0.5654396 , 0.7035421 , 0.7846868 ],\n",
       "         [0.7535642 , 0.79300815, 0.77869105],\n",
       "         [0.66090107, 0.67829335, 0.770115  ],\n",
       "         ...,\n",
       "         [0.97180295, 0.9891434 , 0.9916419 ],\n",
       "         [0.9445234 , 0.9709157 , 0.9721973 ],\n",
       "         [0.9496214 , 0.9681437 , 0.9606601 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.47319368, 0.50450367, 0.49523768],\n",
       "         [0.47477865, 0.48268786, 0.5550888 ],\n",
       "         [0.48815918, 0.5708686 , 0.5832091 ],\n",
       "         ...,\n",
       "         [0.31482306, 0.4316377 , 0.42409423],\n",
       "         [0.33763683, 0.40563703, 0.46876875],\n",
       "         [0.35699514, 0.44501507, 0.49224654]],\n",
       "\n",
       "        [[0.4141889 , 0.46060762, 0.48811284],\n",
       "         [0.42732087, 0.4647619 , 0.482352  ],\n",
       "         [0.43378875, 0.4862971 , 0.5220372 ],\n",
       "         ...,\n",
       "         [0.28502715, 0.35685462, 0.43547106],\n",
       "         [0.32408398, 0.3835254 , 0.40254498],\n",
       "         [0.33862537, 0.38849148, 0.37690854]],\n",
       "\n",
       "        [[0.4420071 , 0.45088515, 0.4897498 ],\n",
       "         [0.46564516, 0.5301569 , 0.45967755],\n",
       "         [0.45542318, 0.53286064, 0.5220826 ],\n",
       "         ...,\n",
       "         [0.27167666, 0.37746355, 0.34951398],\n",
       "         [0.24152386, 0.33458287, 0.39038476],\n",
       "         [0.35940522, 0.3812059 , 0.44554162]]],\n",
       "\n",
       "\n",
       "       [[[0.45940143, 0.42231286, 0.4792272 ],\n",
       "         [0.531367  , 0.47608244, 0.60067415],\n",
       "         [0.43846786, 0.37764773, 0.24900642],\n",
       "         ...,\n",
       "         [0.46298635, 0.40386567, 0.46462134],\n",
       "         [0.359263  , 0.35380653, 0.38164246],\n",
       "         [0.45812714, 0.4969125 , 0.47616702]],\n",
       "\n",
       "        [[0.37283596, 0.428575  , 0.4905086 ],\n",
       "         [0.17972866, 0.2813307 , 0.28199768],\n",
       "         [0.43963537, 0.43237922, 0.40000796],\n",
       "         ...,\n",
       "         [0.21233839, 0.30571008, 0.5316257 ],\n",
       "         [0.730338  , 0.730026  , 0.7367778 ],\n",
       "         [0.2877971 , 0.22786328, 0.4518749 ]],\n",
       "\n",
       "        [[0.38800615, 0.52587366, 0.63878006],\n",
       "         [0.44621766, 0.5475956 , 0.56738186],\n",
       "         [0.5790574 , 0.5930563 , 0.6558428 ],\n",
       "         ...,\n",
       "         [0.03433484, 0.15858445, 0.2037839 ],\n",
       "         [0.04053262, 0.06004167, 0.13481835],\n",
       "         [0.13721362, 0.25098678, 0.24650773]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4081928 , 0.42552373, 0.40676737],\n",
       "         [0.3205934 , 0.37446484, 0.39722216],\n",
       "         [0.37979615, 0.4270379 , 0.40409565],\n",
       "         ...,\n",
       "         [0.33349898, 0.3867282 , 0.36113578],\n",
       "         [0.3556359 , 0.38123387, 0.41039234],\n",
       "         [0.34894818, 0.39325374, 0.3933255 ]],\n",
       "\n",
       "        [[0.3551561 , 0.39375517, 0.4244276 ],\n",
       "         [0.3340131 , 0.4005494 , 0.4104958 ],\n",
       "         [0.33937842, 0.43098727, 0.43181297],\n",
       "         ...,\n",
       "         [0.2990457 , 0.33344316, 0.36768717],\n",
       "         [0.30740008, 0.33248973, 0.34021878],\n",
       "         [0.3179558 , 0.3344971 , 0.30124503]],\n",
       "\n",
       "        [[0.41757384, 0.4077028 , 0.45006248],\n",
       "         [0.3841827 , 0.47214517, 0.39585173],\n",
       "         [0.31594044, 0.41268045, 0.40635577],\n",
       "         ...,\n",
       "         [0.28683996, 0.3527144 , 0.29497135],\n",
       "         [0.2438466 , 0.29550928, 0.31419444],\n",
       "         [0.33179313, 0.35192883, 0.3911909 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-21568b8ad5bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(gen_img[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "image_fns = sorted(glob.glob(\"./gen-imgs/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gen-imgs/000.png\n",
      "./gen-imgs/001.png\n",
      "./gen-imgs/010.png\n",
      "./gen-imgs/100.png\n",
      "./gen-imgs/101.png\n",
      "./gen-imgs/102.png\n",
      "./gen-imgs/103.png\n",
      "./gen-imgs/104.png\n",
      "./gen-imgs/105.png\n",
      "./gen-imgs/106.png\n",
      "./gen-imgs/107.png\n",
      "./gen-imgs/108.png\n",
      "./gen-imgs/109.png\n",
      "./gen-imgs/011.png\n",
      "./gen-imgs/110.png\n",
      "./gen-imgs/111.png\n",
      "./gen-imgs/112.png\n",
      "./gen-imgs/113.png\n",
      "./gen-imgs/114.png\n",
      "./gen-imgs/115.png\n",
      "./gen-imgs/116.png\n",
      "./gen-imgs/117.png\n",
      "./gen-imgs/118.png\n",
      "./gen-imgs/119.png\n",
      "./gen-imgs/012.png\n",
      "./gen-imgs/120.png\n",
      "./gen-imgs/121.png\n",
      "./gen-imgs/122.png\n",
      "./gen-imgs/123.png\n",
      "./gen-imgs/124.png\n",
      "./gen-imgs/125.png\n",
      "./gen-imgs/126.png\n",
      "./gen-imgs/127.png\n",
      "./gen-imgs/128.png\n",
      "./gen-imgs/129.png\n",
      "./gen-imgs/013.png\n",
      "./gen-imgs/130.png\n",
      "./gen-imgs/131.png\n",
      "./gen-imgs/132.png\n",
      "./gen-imgs/133.png\n",
      "./gen-imgs/134.png\n",
      "./gen-imgs/135.png\n",
      "./gen-imgs/136.png\n",
      "./gen-imgs/137.png\n",
      "./gen-imgs/138.png\n",
      "./gen-imgs/139.png\n",
      "./gen-imgs/014.png\n",
      "./gen-imgs/140.png\n",
      "./gen-imgs/141.png\n",
      "./gen-imgs/142.png\n",
      "./gen-imgs/143.png\n",
      "./gen-imgs/144.png\n",
      "./gen-imgs/145.png\n",
      "./gen-imgs/146.png\n",
      "./gen-imgs/147.png\n",
      "./gen-imgs/148.png\n",
      "./gen-imgs/149.png\n",
      "./gen-imgs/015.png\n",
      "./gen-imgs/150.png\n",
      "./gen-imgs/151.png\n",
      "./gen-imgs/152.png\n",
      "./gen-imgs/153.png\n",
      "./gen-imgs/154.png\n",
      "./gen-imgs/155.png\n",
      "./gen-imgs/156.png\n",
      "./gen-imgs/157.png\n",
      "./gen-imgs/158.png\n",
      "./gen-imgs/159.png\n",
      "./gen-imgs/016.png\n",
      "./gen-imgs/160.png\n",
      "./gen-imgs/161.png\n",
      "./gen-imgs/162.png\n",
      "./gen-imgs/163.png\n",
      "./gen-imgs/164.png\n",
      "./gen-imgs/165.png\n",
      "./gen-imgs/166.png\n",
      "./gen-imgs/167.png\n",
      "./gen-imgs/168.png\n",
      "./gen-imgs/169.png\n",
      "./gen-imgs/017.png\n",
      "./gen-imgs/170.png\n",
      "./gen-imgs/171.png\n",
      "./gen-imgs/172.png\n",
      "./gen-imgs/173.png\n",
      "./gen-imgs/174.png\n",
      "./gen-imgs/175.png\n",
      "./gen-imgs/176.png\n",
      "./gen-imgs/177.png\n",
      "./gen-imgs/178.png\n",
      "./gen-imgs/179.png\n",
      "./gen-imgs/018.png\n",
      "./gen-imgs/180.png\n",
      "./gen-imgs/181.png\n",
      "./gen-imgs/182.png\n",
      "./gen-imgs/183.png\n",
      "./gen-imgs/184.png\n",
      "./gen-imgs/185.png\n",
      "./gen-imgs/186.png\n",
      "./gen-imgs/187.png\n",
      "./gen-imgs/188.png\n",
      "./gen-imgs/189.png\n",
      "./gen-imgs/019.png\n",
      "./gen-imgs/190.png\n",
      "./gen-imgs/191.png\n",
      "./gen-imgs/192.png\n",
      "./gen-imgs/193.png\n",
      "./gen-imgs/194.png\n",
      "./gen-imgs/195.png\n",
      "./gen-imgs/196.png\n",
      "./gen-imgs/197.png\n",
      "./gen-imgs/198.png\n",
      "./gen-imgs/199.png\n",
      "./gen-imgs/002.png\n",
      "./gen-imgs/020.png\n",
      "./gen-imgs/200.png\n",
      "./gen-imgs/201.png\n",
      "./gen-imgs/202.png\n",
      "./gen-imgs/203.png\n",
      "./gen-imgs/204.png\n",
      "./gen-imgs/205.png\n",
      "./gen-imgs/206.png\n",
      "./gen-imgs/207.png\n",
      "./gen-imgs/208.png\n",
      "./gen-imgs/209.png\n",
      "./gen-imgs/021.png\n",
      "./gen-imgs/210.png\n",
      "./gen-imgs/211.png\n",
      "./gen-imgs/212.png\n",
      "./gen-imgs/213.png\n",
      "./gen-imgs/214.png\n",
      "./gen-imgs/215.png\n",
      "./gen-imgs/216.png\n",
      "./gen-imgs/217.png\n",
      "./gen-imgs/218.png\n",
      "./gen-imgs/219.png\n",
      "./gen-imgs/022.png\n",
      "./gen-imgs/220.png\n",
      "./gen-imgs/221.png\n",
      "./gen-imgs/222.png\n",
      "./gen-imgs/223.png\n",
      "./gen-imgs/224.png\n",
      "./gen-imgs/225.png\n",
      "./gen-imgs/226.png\n",
      "./gen-imgs/227.png\n",
      "./gen-imgs/228.png\n",
      "./gen-imgs/229.png\n",
      "./gen-imgs/023.png\n",
      "./gen-imgs/230.png\n",
      "./gen-imgs/231.png\n",
      "./gen-imgs/232.png\n",
      "./gen-imgs/233.png\n",
      "./gen-imgs/234.png\n",
      "./gen-imgs/235.png\n",
      "./gen-imgs/236.png\n",
      "./gen-imgs/237.png\n",
      "./gen-imgs/238.png\n",
      "./gen-imgs/239.png\n",
      "./gen-imgs/024.png\n",
      "./gen-imgs/025.png\n",
      "./gen-imgs/026.png\n",
      "./gen-imgs/027.png\n",
      "./gen-imgs/028.png\n",
      "./gen-imgs/029.png\n",
      "./gen-imgs/003.png\n",
      "./gen-imgs/030.png\n",
      "./gen-imgs/031.png\n",
      "./gen-imgs/032.png\n",
      "./gen-imgs/033.png\n",
      "./gen-imgs/034.png\n",
      "./gen-imgs/035.png\n",
      "./gen-imgs/036.png\n",
      "./gen-imgs/037.png\n",
      "./gen-imgs/038.png\n",
      "./gen-imgs/039.png\n",
      "./gen-imgs/004.png\n",
      "./gen-imgs/040.png\n",
      "./gen-imgs/041.png\n",
      "./gen-imgs/042.png\n",
      "./gen-imgs/043.png\n",
      "./gen-imgs/044.png\n",
      "./gen-imgs/045.png\n",
      "./gen-imgs/046.png\n",
      "./gen-imgs/047.png\n",
      "./gen-imgs/048.png\n",
      "./gen-imgs/049.png\n",
      "./gen-imgs/005.png\n",
      "./gen-imgs/050.png\n",
      "./gen-imgs/051.png\n",
      "./gen-imgs/052.png\n",
      "./gen-imgs/053.png\n",
      "./gen-imgs/054.png\n",
      "./gen-imgs/055.png\n",
      "./gen-imgs/056.png\n",
      "./gen-imgs/057.png\n",
      "./gen-imgs/058.png\n",
      "./gen-imgs/059.png\n",
      "./gen-imgs/006.png\n",
      "./gen-imgs/060.png\n",
      "./gen-imgs/061.png\n",
      "./gen-imgs/062.png\n",
      "./gen-imgs/063.png\n",
      "./gen-imgs/064.png\n",
      "./gen-imgs/065.png\n",
      "./gen-imgs/066.png\n",
      "./gen-imgs/067.png\n",
      "./gen-imgs/068.png\n",
      "./gen-imgs/069.png\n",
      "./gen-imgs/007.png\n",
      "./gen-imgs/070.png\n",
      "./gen-imgs/071.png\n",
      "./gen-imgs/072.png\n",
      "./gen-imgs/073.png\n",
      "./gen-imgs/074.png\n",
      "./gen-imgs/075.png\n",
      "./gen-imgs/076.png\n",
      "./gen-imgs/077.png\n",
      "./gen-imgs/078.png\n",
      "./gen-imgs/079.png\n",
      "./gen-imgs/008.png\n",
      "./gen-imgs/080.png\n",
      "./gen-imgs/081.png\n",
      "./gen-imgs/082.png\n",
      "./gen-imgs/083.png\n",
      "./gen-imgs/084.png\n",
      "./gen-imgs/085.png\n",
      "./gen-imgs/086.png\n",
      "./gen-imgs/087.png\n",
      "./gen-imgs/088.png\n",
      "./gen-imgs/089.png\n",
      "./gen-imgs/009.png\n",
      "./gen-imgs/090.png\n",
      "./gen-imgs/091.png\n",
      "./gen-imgs/092.png\n",
      "./gen-imgs/093.png\n",
      "./gen-imgs/094.png\n",
      "./gen-imgs/095.png\n",
      "./gen-imgs/096.png\n",
      "./gen-imgs/097.png\n",
      "./gen-imgs/098.png\n",
      "./gen-imgs/099.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for image_name in image_fns:\n",
    "    split_name = image_name.split('/')\n",
    "    filename = split_name[-1]\n",
    "    path = \"/\".join(split_name[0:2])\n",
    "    \n",
    "    split_filename = filename.split('_')[-1]\n",
    "    corrected_filename = split_filename.rjust(7, '0')\n",
    "    full_path = \"/\".join([path, corrected_filename])\n",
    "    print(full_path)\n",
    "    os.rename(image_name, full_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(glob.glob(\"./gen-imgs/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('./gen-imgs/first_attempt.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
