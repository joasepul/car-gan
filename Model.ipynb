{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, merge, Concatenate, Dense, Dropout, Conv2D, Add, Dot, Lambda, Conv2DTranspose, Dot, Activation, Reshape, BatchNormalization, UpSampling2D, AveragePooling2D, GlobalAveragePooling2D, Multiply, LeakyReLU, Flatten, MaxPool2D \n",
    "from keras.layers.convolutional import Convolution2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Jose Sepulveda\n",
    "# Description: This is a keras implementation of spectral normalization.\n",
    "#              This was proposed in this paper: https://arxiv.org/pdf/1802.05957.pdf\n",
    "#\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# Stochastic Gradient Descent with Spectral Normalization:\n",
    "#   1) Initialize a random vector u, initialized from an isotropic distribution.\n",
    "#   2) Use the Power iteration method with this vector u on the matrix of wieghts\n",
    "#      to obtain two approximations of eigenvectors.\n",
    "#   3) Calculate the spectral norm of the wieghts matrix.\n",
    "#   4) Update wieghts using vanilla SGD using the spectral norm of the wieghts matrix.\n",
    "\n",
    "def spectral_norm(w):\n",
    "    \"\"\"\n",
    "        Input: tensor of wieghts\n",
    "        Output: SN tensor of wieghts\n",
    "    \"\"\"\n",
    "    def l2_norm(v):\n",
    "        return K.sum(v ** 2) ** 0.5\n",
    "\n",
    "    w_dim = w.shape.as_list()[-1]\n",
    "    # Initialize random vector u\n",
    "    u = K.random_normal(shape=[1, w_dim])\n",
    "\n",
    "    # We need to flatten the wieghts\n",
    "    w_flat = K.reshape(w, [-1, w_dim])\n",
    "\n",
    "    # Power iteration method\n",
    "    v = K.dot(u, K.transpose(w_flat))\n",
    "    v = v / l2_norm(v)\n",
    "    u = K.dot(v, w_flat)\n",
    "    u = u / l2_norm(u)\n",
    "\n",
    "    # Calculate the SN of W\n",
    "    sigma = K.dot(K.dot(v, w_flat), K.transpose(u))\n",
    "    w_sn = w_flat / sigma\n",
    "\n",
    "    # Update wieghts\n",
    "    w_sn = K.reshape(w_sn, w.shape.as_list())\n",
    "    return w_sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlockDown(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "    # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same', strides=2)(input_layer)\n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    #SECOND BLOCK\n",
    "    \n",
    "   \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same')(resblock)\n",
    "     # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Downsample\n",
    "    #resblock = AveragePooling2D()(resblock)\n",
    "    \n",
    "    # Time for the shortcut connection!\n",
    "    \n",
    "    shortcut_identity = Conv2D(channel_size * channel_multiplier, 3, padding='same', strides=2)(input_layer)\n",
    "    #shortcut_identity = AveragePooling2D()(shortcut_identity)\n",
    "    \n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    output_layer = LeakyReLU()(output_layer)\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlockUp(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "    # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2DTranspose(channel_size * channel_multiplier, 3, padding='same', strides=2)(input_layer)\n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    #SECOND BLOCK\n",
    "    \n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2DTranspose(channel_size * channel_multiplier, 3, padding='same')(resblock)\n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock)\n",
    "    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    \n",
    "    # Downsample\n",
    "    #resblock = AveragePooling2D()(resblock)\n",
    "    \n",
    "    # Time for the shortcut connection!\n",
    "    \n",
    "    shortcut_identity = Conv2DTranspose(channel_size * channel_multiplier, 1, padding='same', strides=2)(input_layer)\n",
    "    #shortcut_identity = AveragePooling2D()(shortcut_identity)\n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    output_layer = LeakyReLU()(output_layer)\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlock(input_shape, channel_size, channel_multiplier=1, name=None):\n",
    "     # Resblock architecture\n",
    "    # 1 BatchNorm \n",
    "    # 2 ReLU activation\n",
    "    # 3 Conv layer\n",
    "    # 4 BatchNorm\n",
    "    # 5 ReLU activation\n",
    "    # 6 Conv layer\n",
    "    # 7 Sum with input \n",
    "    \n",
    "    #FIRST BLOCK\n",
    "    #input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same')(input_layer)\n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(resblock) \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)\n",
    "    #SECOND BLOCK   \n",
    "    \n",
    "    # Convolution size 3 filter as per paper\n",
    "    # Need to spectrally normalize here somehow\n",
    "    resblock = Conv2D(channel_size * channel_multiplier, 3, padding='same')(resblock)\n",
    "    # BatchNorm - needs to be conditional\n",
    "    resblock = BatchNormalization()(input_layer)    \n",
    "    # Relu\n",
    "    resblock = Activation('relu')(resblock)    \n",
    "    # Time for the shortcut connection!   \n",
    "    shortcut_identity = Conv2D(channel_size * channel_multiplier, 1, padding='same')(input_layer)\n",
    "    output_layer = Add()([shortcut_identity, resblock])\n",
    "    output_layer = LeakyReLU()(output_layer)\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def SelfAttentionBlock(input_shape, name=None):\n",
    "    # f = conv\n",
    "    channels = input_shape[-1]\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    f = Conv2D(channels // 8, 1, padding='same')(input_layer)\n",
    "    # f = maxpooling\n",
    "    f = MaxPool2D(pool_size=2, strides=2, padding='same')(f)\n",
    "    \n",
    "    g = Conv2D(channels // 8, 1, padding='same')(input_layer)\n",
    "    \n",
    "    h = Conv2D(channels // 2, 1, padding='same')(input_layer)\n",
    "    h = MaxPool2D(pool_size=2, strides=2, padding='same')(h)\n",
    "    \n",
    "    \n",
    "    g = Reshape((-1, g.shape[-1]))(g)\n",
    "    f = Reshape((-1, g.shape[-1]))(f)\n",
    "    s = Dot(-1)([g, f])\n",
    "    print(\"Shape of s:{}\".format(s.shape))\n",
    "    beta = Activation('softmax')(s)\n",
    "    print(\"Shape of beta:{}\".format(beta.shape))\n",
    "    h = Reshape((-1, h.shape[-1]))(h)\n",
    "    print(\"Shape of h:{}\".format(h.shape))\n",
    "    o = tf.matmul(beta, h)\n",
    "    \n",
    "    gamma = Conv2D(channels, (1, 1), padding='same', use_bias=False, kernel_initializer='he_normal')(input_layer)\n",
    "    #gamma = Reshape((-1, channels // 2))(g)\n",
    "    #print(gamma.shape)\n",
    "    a, x, y ,z = input_layer.shape\n",
    "    print(o.shape)\n",
    "    #o = K.reshape(o, shape=[x,y,z, channels // 2])\n",
    "    o = Reshape((-1,z,channels//2))(o)\n",
    "    o = Conv2D(channels, kernel_size=1, strides=1)(o)\n",
    "  \n",
    "    Wz_yi = gamma * o\n",
    "    output_layer = Add()([Wz_yi, input_layer])\n",
    "    #output_layer = gamma*o + input_layer\n",
    "    \n",
    "    return Model(input_layer, output_layer, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def GlobalSumPooling2D(name=None):\n",
    "    return Lambda(lambda inputs: K.sum(inputs, axis=[1, 2]), name=name)\n",
    "        \n",
    "# Discriminator test\n",
    "def build_discriminator(channel_multiplier=64):\n",
    "    input_shape = (128,128,3)\n",
    "    model_input = Input(shape=input_shape, name=\"D_input\")\n",
    "    resblockdown1 = ResBlockDown(input_shape=input_shape,channel_size=1, channel_multiplier=channel_multiplier, name='D_resblock_down_1')\n",
    "    h = resblockdown1(model_input)\n",
    "#     selfattentionblock = SelfAttentionBlock(input_shape=(64,64,32), name='D_self_attention_block')\n",
    "#     h = selfattentionblock(h)\n",
    "    # Non local block should be here\n",
    "    #print(h.shape)\n",
    "    ch = channel_multiplier\n",
    "    x = input_shape[0]\n",
    "    y = input_shape[1]\n",
    "    resblockdown2 = ResBlockDown(input_shape=(x,y,channel_multiplier),channel_size=2, channel_multiplier=channel_multiplier, name='D_resblock_down_2')\n",
    "    h = resblockdown2(h)\n",
    "    #print(h.shape)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    resblockdown4 = ResBlockDown(input_shape=(x,y,ch),channel_size=4, channel_multiplier=channel_multiplier, name='D_resblock_down_4')\n",
    "    h = resblockdown4(h)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    #print(h.shape)\n",
    "    resblockdown8 = ResBlockDown(input_shape=(x,y,ch),channel_size=8, channel_multiplier=channel_multiplier, name='D_resblock_down_8')\n",
    "    \n",
    "    h = resblockdown8(h)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    \n",
    "\n",
    "    resblockdown16 = ResBlockDown(input_shape=(x,y,ch),channel_size=16, channel_multiplier=channel_multiplier, name='D_resblock_down_16')\n",
    "    h = resblockdown16(h)\n",
    "    x = x // 2\n",
    "    y = y // 2\n",
    "    ch = ch * 2\n",
    "    resblock16 = ResBlock(input_shape=(x,y,ch),channel_size=16, channel_multiplier=channel_multiplier, name='D_resblock_16')\n",
    "    h = resblock16(h)\n",
    "\n",
    "    h = Activation('relu', name=\"D_relu\")(h)\n",
    "    h = GlobalAveragePooling2D(name=\"D_global_avg_pooling_2D\")(h)\n",
    "    model_output = Dense(1, name=\"D_dense\")(h)\n",
    "    model = Model(model_input, model_output, name=\"Discriminator\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only noise, non conditional\n",
    "def build_generator(channel_multiplier=64):\n",
    "\n",
    "    model_input = Input(shape=(128,), name=\"G_input\")\n",
    "    h = Dense(4*4*16*channel_multiplier, name=\"G_dense\")(model_input)\n",
    "    h = Reshape((4,4,16*channel_multiplier))(h) # 512 = 16*ch\n",
    "    resblockup16 = ResBlockUp(input_shape=(4,4,1024), channel_size=16, channel_multiplier=channel_multiplier, name=\"G_resblock_up_16\")\n",
    "    h = resblockup16(h)\n",
    "    resblockup8 = ResBlockUp(input_shape=(8,8,1024), channel_size=8, channel_multiplier=channel_multiplier, name=\"G_resblock_up_8\")\n",
    "    h = resblockup8(h)\n",
    "    resblockup4 = ResBlockUp(input_shape=(16,16,512), channel_size=4, channel_multiplier=channel_multiplier, name=\"G_resblock_up_4\")\n",
    "    h = resblockup4(h)\n",
    "\n",
    "    resblockup2 = ResBlockUp(input_shape=(64,64,256), channel_size=2, channel_multiplier=channel_multiplier, name=\"G_resblock_up_2\")\n",
    "    h = resblockup2(h)\n",
    "#     need to debug the following\n",
    "    #selfattentionblock = SelfAttentionBlock(input_shape=(64,64,32), name='G_self_attention_block')\n",
    "    #h = selfattentionblock(h)\n",
    "    resblockup1 = ResBlockUp(input_shape=(128,128,128), channel_size=1, channel_multiplier=channel_multiplier, name=\"G_resblock_up_1\")\n",
    "    h = resblockup1(h)\n",
    "    #print(h.shape)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "    model_output = Conv2D(3, kernel_size=3, strides=1, padding='same', activation='tanh')(h)\n",
    "    \n",
    "    return Model(model_input, model_output, name=\"Generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def UNETGenerator(input_img_dim, num_output_channels):\n",
    "    \"\"\"\n",
    "    Creates the generator according to the specs in the paper below.\n",
    "    It's basically a skip layer AutoEncoder\n",
    "    Generator does the following:\n",
    "    1. Takes in an image\n",
    "    2. Generates an image from this image\n",
    "    Differs from a standard GAN because the image isn't random.\n",
    "    This model tries to learn a mapping from a suboptimal image to an optimal image.\n",
    "    [https://arxiv.org/pdf/1611.07004v1.pdf][5. Appendix]\n",
    "    :param input_img_dim: (channel, height, width)\n",
    "    :param output_img_dim: (channel, height, width)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # -------------------------------\n",
    "    # ENCODER\n",
    "    # C64-C128-C256-C512-C512-C512-C512-C512\n",
    "    # 1 layer block = Conv - BN - LeakyRelu\n",
    "    # -------------------------------\n",
    "    stride = 2\n",
    "    merge_mode = 'concat'\n",
    "\n",
    "    # batch norm mode\n",
    "    bn_mode = 2\n",
    "\n",
    "    # batch norm merge axis\n",
    "    bn_axis = 1\n",
    "\n",
    "    input_layer = Input(shape=input_img_dim, name=\"unet_input\")\n",
    "\n",
    "    # 1 encoder C64\n",
    "    # skip batchnorm on this layer on purpose (from paper)\n",
    "    en_1 = Conv2D(64, 4, strides=2, padding=\"same\")(input_layer)\n",
    "    en_1 = LeakyReLU(alpha=0.2)(en_1)\n",
    "    #print(en_1.shape)\n",
    "\n",
    "    # 2 encoder C128\n",
    "    en_2 = Conv2D(128, 4, strides=2,padding='same')(en_1)\n",
    "    en_2 = BatchNormalization()(en_2)\n",
    "    en_2 = LeakyReLU(alpha=0.2)(en_2)\n",
    "    #print(en_2.shape)\n",
    "\n",
    "    # 3 encoder C256\n",
    "    en_3 = Conv2D(256, 4, padding='same', strides=2)(en_2)\n",
    "    en_3 = BatchNormalization()(en_3)\n",
    "    en_3 = LeakyReLU(alpha=0.2)(en_3)\n",
    "    #print(en_3.shape)\n",
    "\n",
    "    # 4 encoder C512\n",
    "    en_4 = Conv2D(512, 4, padding='same', strides=2)(en_3)\n",
    "    en_4 = BatchNormalization()(en_4)\n",
    "    en_4 = LeakyReLU(alpha=0.2)(en_4)\n",
    "   # print(en_4.shape)\n",
    "\n",
    "    # 5 encoder C512\n",
    "    en_5 = Conv2D(512, 4, padding='same', strides=2)(en_4)\n",
    "    en_5 = BatchNormalization()(en_5)\n",
    "    en_5 = LeakyReLU(alpha=0.2)(en_5)\n",
    "    #print(en_5.shape)\n",
    "\n",
    "    # 6 encoder C512\n",
    "    en_6 = Conv2D(512, 4, padding='same', strides=2)(en_5)\n",
    "    en_6 = BatchNormalization()(en_6)\n",
    "    en_6 = LeakyReLU(alpha=0.2)(en_6)\n",
    "   #print(en_6.shape)\n",
    "\n",
    "    # 7 encoder C512\n",
    "    en_7 = Conv2D(512, 4, padding='same', strides=2)(en_6)\n",
    "    en_7 = BatchNormalization()(en_7)\n",
    "    en_7 = LeakyReLU(alpha=0.2)(en_7)\n",
    "    #print(en_7.shape)\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # DECODER\n",
    "    # CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
    "    # 1 layer block = Conv - Upsample - BN - DO - Relu\n",
    "    # also adds skip connections (merge). Takes input from previous layer matching encoder layer\n",
    "    # -------------------------------\n",
    "\n",
    "\n",
    "    # 2 decoder CD1024 (decodes en_7)\n",
    "    de_2 = UpSampling2D(size=(2, 2))(en_7)\n",
    "    de_2 = Conv2D(1024, 4, padding='same')(de_2)\n",
    "    de_2 = BatchNormalization()(de_2)\n",
    "    de_2 = Dropout(rate=0.5)(de_2)\n",
    "    de_2 = Concatenate()([de_2, en_6])\n",
    "    de_2 = Activation('relu')(de_2)\n",
    "\n",
    "    # 3 decoder CD1024 (decodes en_6)\n",
    "    de_3 = UpSampling2D(size=(2, 2))(de_2)\n",
    "    de_3 = Conv2D(1024, 4, padding='same')(de_3)\n",
    "    de_3 = BatchNormalization()(de_3)\n",
    "    de_3 = Dropout(rate=0.5)(de_3)\n",
    "    de_3 = Concatenate()([de_3, en_5])\n",
    "    de_3 = Activation('relu')(de_3)\n",
    "\n",
    "    # 4 decoder CD1024 (decodes en_5)\n",
    "    de_4 = UpSampling2D(size=(2, 2))(de_3)\n",
    "    de_4 = Conv2D(1024, 4, padding='same')(de_4)\n",
    "    de_4 = BatchNormalization()(de_4)\n",
    "    de_4 = Dropout(rate=0.5)(de_4)\n",
    "    de_4 = Concatenate()([de_4, en_4])\n",
    "    de_4 = Activation('relu')(de_4)\n",
    "\n",
    "    # 5 decoder CD1024 (decodes en_4)\n",
    "    de_5 = UpSampling2D(size=(2, 2))(de_4)\n",
    "    de_5 = Conv2D(1024, 4, padding='same')(de_5)\n",
    "    de_5 = BatchNormalization()(de_5)\n",
    "    de_5 = Dropout(rate=0.5)(de_5)\n",
    "    de_5 = Concatenate()([de_5, en_3])\n",
    "    de_5 = Activation('relu')(de_5)\n",
    "\n",
    "    # 6 decoder C512 (decodes en_3)\n",
    "    de_6 = UpSampling2D(size=(2, 2))(de_5)\n",
    "    de_6 = Conv2D(512, 4, padding='same')(de_6)\n",
    "    de_6 = BatchNormalization()(de_6)\n",
    "    de_6 = Dropout(rate=0.5)(de_6)\n",
    "    de_6 = Concatenate()([de_6, en_2])\n",
    "    de_6 = Activation('relu')(de_6)\n",
    "\n",
    "    # 7 decoder CD256 (decodes en_2)\n",
    "    de_7 = UpSampling2D(size=(2, 2))(de_6)\n",
    "    de_7 = Conv2D(256, 4, padding='same')(de_7)\n",
    "    de_7 = BatchNormalization()(de_7)\n",
    "    de_7 = Dropout(rate=0.5)(de_7)\n",
    "    de_7 = Concatenate()([de_7, en_1])\n",
    "    de_7 = Activation('relu')(de_7)\n",
    "\n",
    "    # After the last layer in the decoder, a conv is applied\n",
    "    # to map to the number of output channels (3 in general,\n",
    "    # except in colorization, where it is 2), followed by a Tanh\n",
    "    # function.\n",
    "    de_8 = UpSampling2D(size=(2, 2))(de_7)\n",
    "    de_8 = Conv2D(num_output_channels, 4, padding='same')(de_8)\n",
    "    de_8 = Activation('tanh')(de_8)\n",
    "\n",
    "    unet_generator = Model(input_layer, de_8, name='unet_generator')\n",
    "    return unet_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "def dataLoader(datapath):\n",
    "    edge_filepaths = sorted(glob.glob('./edge-data/'+'edge-1[0-9][0-9][0-9].png')) #sorted(glob.glob(datapath+'edge-*.png'))\n",
    "    img_filepaths = sorted(glob.glob('./edge-data/'+'1[0-9][0-9][0-9].png')) #sorted(glob.glob(datapath+'*.png'))\n",
    "    edges = []\n",
    "    imgs = []\n",
    "    for edge_fp, img_fp in zip(edge_filepaths,img_filepaths):\n",
    "        edge = cv2.imread(edge_fp, 0)\n",
    "        img = cv2.imread(img_fp)\n",
    "        edge[edge != 255] = 0\n",
    "        edge = edge // 255\n",
    "        edge = np.reshape(edge, (edge.shape[0], edge.shape[1], 1))\n",
    "        edges.append(edge)\n",
    "        imgs.append(img)\n",
    "        \n",
    "    return np.array(edges), np.array(imgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, imgs = dataLoader('./edge-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers \n",
    "import keras.backend as K\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    " \n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.local_variables_initializer())\n",
    "# Create a session with the above options specified.\n",
    "K.tensorflow_backend.set_session(sess)\n",
    "###################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperperemeter\n",
    "BATCHSIZE=9\n",
    "LEARNING_RATE = 0.01\n",
    "TRAINING_RATIO = 1\n",
    "BETA_1 = 0.0\n",
    "BETA_2 = 0.9\n",
    "EPOCHS = 500\n",
    "BN_MIMENTUM = 0.9\n",
    "BN_EPSILON  = 0.00002\n",
    "SAVE_DIR = 'gen-imgs/'\n",
    "\n",
    "GENERATE_ROW_NUM = 3\n",
    "GENERATE_BATCHSIZE = GENERATE_ROW_NUM*GENERATE_ROW_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs/255*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jose\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#DISCRIMINATOR MODEL\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jose\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Adversarial model\n",
    "optimizer = optimizer = Adam(0.0002, 0.5)\n",
    "input_edge = Input(shape=(128,128,1))\n",
    "unet_generator = UNETGenerator((128,128,1),3)\n",
    "generated_image = unet_generator(input_edge)\n",
    "discriminator_output = discriminator(generated_image)\n",
    "adversarial_net = Model(input_edge, discriminator_output)\n",
    "adversarial_net.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_img(img_list, epoch):\n",
    "    for i, img in enumerate(img_list):\n",
    "        if i!=0:\n",
    "            fig = np.concatenate((fig,img),axis=1)\n",
    "        else:\n",
    "            fig = img\n",
    "    print('plot generated_image')\n",
    "    plt.imsave('gen-imgs/epoch_{}.png'.format(epoch), fig)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0/111 [..............................] - ETA: 0sWARNING:tensorflow:From C:\\Users\\Jose\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "110/111 [============================>.] - ETA: 2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot generated_image\n",
      "110/111 [============================>.] - ETA: 2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot generated_image\n",
      " 52/111 [=============>................] - ETA: 2:12"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f6ff657eb221>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBATCHSIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0ma_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madversarial_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mgen_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munet_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0msave_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    s = np.arange(imgs.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    X = imgs[s]\n",
    "    Y = edges[s]\n",
    "\n",
    "\n",
    "    #print(\"epoch {} of {}\".format(epoch+1, EPOCHS))\n",
    "    num_batches = int(X.shape[0] // BATCHSIZE)\n",
    "    #print(\"number of batches: {}\".format(int(X.shape[0] // (BATCHSIZE))))\n",
    "    progress_bar = Progbar(target=int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO)))\n",
    "    minibatches_size = BATCHSIZE * TRAINING_RATIO\n",
    "    start_time = time()\n",
    "    \n",
    "    for index in range(int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO))):\n",
    "        progress_bar.update(index)\n",
    "        indices = np.arange(X.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        indices = indices[:BATCHSIZE]\n",
    "        image_batch = X[indices]\n",
    "        edges_batch = Y[indices]\n",
    "        #print(edges_batch.shape)\n",
    "        labels = np.ones([2*BATCHSIZE,1], dtype=np.float32)\n",
    "        labels[BATCHSIZE:,:] = 0.\n",
    "        \n",
    "        images_fake = unet_generator.predict(edges_batch)\n",
    "        train_batch = np.concatenate((image_batch, images_fake))\n",
    "        d_loss = discriminator.train_on_batch(train_batch, labels)\n",
    "        y = np.ones([BATCHSIZE, 1], dtype=np.float32)\n",
    "        a_loss = adversarial_net.train_on_batch(edges_batch, y)\n",
    "    gen_imgs = unet_generator.predict(edges_batch)\n",
    "    save_img(gen_imgs, epoch)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_img = generator.predict(test_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "image_fns = sorted(glob.glob(\"./gen-imgs/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gen-imgs/000.png\n",
      "./gen-imgs/001.png\n",
      "./gen-imgs/010.png\n",
      "./gen-imgs/100.png\n",
      "./gen-imgs/101.png\n",
      "./gen-imgs/102.png\n",
      "./gen-imgs/103.png\n",
      "./gen-imgs/104.png\n",
      "./gen-imgs/105.png\n",
      "./gen-imgs/106.png\n",
      "./gen-imgs/107.png\n",
      "./gen-imgs/108.png\n",
      "./gen-imgs/109.png\n",
      "./gen-imgs/011.png\n",
      "./gen-imgs/110.png\n",
      "./gen-imgs/111.png\n",
      "./gen-imgs/112.png\n",
      "./gen-imgs/113.png\n",
      "./gen-imgs/114.png\n",
      "./gen-imgs/115.png\n",
      "./gen-imgs/116.png\n",
      "./gen-imgs/117.png\n",
      "./gen-imgs/118.png\n",
      "./gen-imgs/119.png\n",
      "./gen-imgs/012.png\n",
      "./gen-imgs/120.png\n",
      "./gen-imgs/121.png\n",
      "./gen-imgs/122.png\n",
      "./gen-imgs/123.png\n",
      "./gen-imgs/124.png\n",
      "./gen-imgs/125.png\n",
      "./gen-imgs/126.png\n",
      "./gen-imgs/127.png\n",
      "./gen-imgs/128.png\n",
      "./gen-imgs/129.png\n",
      "./gen-imgs/013.png\n",
      "./gen-imgs/130.png\n",
      "./gen-imgs/131.png\n",
      "./gen-imgs/132.png\n",
      "./gen-imgs/133.png\n",
      "./gen-imgs/134.png\n",
      "./gen-imgs/135.png\n",
      "./gen-imgs/136.png\n",
      "./gen-imgs/137.png\n",
      "./gen-imgs/138.png\n",
      "./gen-imgs/139.png\n",
      "./gen-imgs/014.png\n",
      "./gen-imgs/140.png\n",
      "./gen-imgs/141.png\n",
      "./gen-imgs/142.png\n",
      "./gen-imgs/143.png\n",
      "./gen-imgs/144.png\n",
      "./gen-imgs/145.png\n",
      "./gen-imgs/146.png\n",
      "./gen-imgs/147.png\n",
      "./gen-imgs/148.png\n",
      "./gen-imgs/149.png\n",
      "./gen-imgs/015.png\n",
      "./gen-imgs/150.png\n",
      "./gen-imgs/151.png\n",
      "./gen-imgs/152.png\n",
      "./gen-imgs/153.png\n",
      "./gen-imgs/154.png\n",
      "./gen-imgs/155.png\n",
      "./gen-imgs/156.png\n",
      "./gen-imgs/157.png\n",
      "./gen-imgs/158.png\n",
      "./gen-imgs/159.png\n",
      "./gen-imgs/016.png\n",
      "./gen-imgs/160.png\n",
      "./gen-imgs/161.png\n",
      "./gen-imgs/162.png\n",
      "./gen-imgs/163.png\n",
      "./gen-imgs/164.png\n",
      "./gen-imgs/165.png\n",
      "./gen-imgs/166.png\n",
      "./gen-imgs/167.png\n",
      "./gen-imgs/168.png\n",
      "./gen-imgs/169.png\n",
      "./gen-imgs/017.png\n",
      "./gen-imgs/170.png\n",
      "./gen-imgs/171.png\n",
      "./gen-imgs/172.png\n",
      "./gen-imgs/173.png\n",
      "./gen-imgs/174.png\n",
      "./gen-imgs/175.png\n",
      "./gen-imgs/176.png\n",
      "./gen-imgs/177.png\n",
      "./gen-imgs/178.png\n",
      "./gen-imgs/179.png\n",
      "./gen-imgs/018.png\n",
      "./gen-imgs/180.png\n",
      "./gen-imgs/181.png\n",
      "./gen-imgs/182.png\n",
      "./gen-imgs/183.png\n",
      "./gen-imgs/184.png\n",
      "./gen-imgs/185.png\n",
      "./gen-imgs/186.png\n",
      "./gen-imgs/187.png\n",
      "./gen-imgs/188.png\n",
      "./gen-imgs/189.png\n",
      "./gen-imgs/019.png\n",
      "./gen-imgs/190.png\n",
      "./gen-imgs/191.png\n",
      "./gen-imgs/192.png\n",
      "./gen-imgs/193.png\n",
      "./gen-imgs/194.png\n",
      "./gen-imgs/195.png\n",
      "./gen-imgs/196.png\n",
      "./gen-imgs/197.png\n",
      "./gen-imgs/198.png\n",
      "./gen-imgs/199.png\n",
      "./gen-imgs/002.png\n",
      "./gen-imgs/020.png\n",
      "./gen-imgs/200.png\n",
      "./gen-imgs/201.png\n",
      "./gen-imgs/202.png\n",
      "./gen-imgs/203.png\n",
      "./gen-imgs/204.png\n",
      "./gen-imgs/205.png\n",
      "./gen-imgs/206.png\n",
      "./gen-imgs/207.png\n",
      "./gen-imgs/208.png\n",
      "./gen-imgs/209.png\n",
      "./gen-imgs/021.png\n",
      "./gen-imgs/210.png\n",
      "./gen-imgs/211.png\n",
      "./gen-imgs/212.png\n",
      "./gen-imgs/213.png\n",
      "./gen-imgs/214.png\n",
      "./gen-imgs/215.png\n",
      "./gen-imgs/216.png\n",
      "./gen-imgs/217.png\n",
      "./gen-imgs/218.png\n",
      "./gen-imgs/219.png\n",
      "./gen-imgs/022.png\n",
      "./gen-imgs/220.png\n",
      "./gen-imgs/221.png\n",
      "./gen-imgs/222.png\n",
      "./gen-imgs/223.png\n",
      "./gen-imgs/224.png\n",
      "./gen-imgs/225.png\n",
      "./gen-imgs/226.png\n",
      "./gen-imgs/227.png\n",
      "./gen-imgs/228.png\n",
      "./gen-imgs/229.png\n",
      "./gen-imgs/023.png\n",
      "./gen-imgs/230.png\n",
      "./gen-imgs/231.png\n",
      "./gen-imgs/232.png\n",
      "./gen-imgs/233.png\n",
      "./gen-imgs/234.png\n",
      "./gen-imgs/235.png\n",
      "./gen-imgs/236.png\n",
      "./gen-imgs/237.png\n",
      "./gen-imgs/238.png\n",
      "./gen-imgs/239.png\n",
      "./gen-imgs/024.png\n",
      "./gen-imgs/025.png\n",
      "./gen-imgs/026.png\n",
      "./gen-imgs/027.png\n",
      "./gen-imgs/028.png\n",
      "./gen-imgs/029.png\n",
      "./gen-imgs/003.png\n",
      "./gen-imgs/030.png\n",
      "./gen-imgs/031.png\n",
      "./gen-imgs/032.png\n",
      "./gen-imgs/033.png\n",
      "./gen-imgs/034.png\n",
      "./gen-imgs/035.png\n",
      "./gen-imgs/036.png\n",
      "./gen-imgs/037.png\n",
      "./gen-imgs/038.png\n",
      "./gen-imgs/039.png\n",
      "./gen-imgs/004.png\n",
      "./gen-imgs/040.png\n",
      "./gen-imgs/041.png\n",
      "./gen-imgs/042.png\n",
      "./gen-imgs/043.png\n",
      "./gen-imgs/044.png\n",
      "./gen-imgs/045.png\n",
      "./gen-imgs/046.png\n",
      "./gen-imgs/047.png\n",
      "./gen-imgs/048.png\n",
      "./gen-imgs/049.png\n",
      "./gen-imgs/005.png\n",
      "./gen-imgs/050.png\n",
      "./gen-imgs/051.png\n",
      "./gen-imgs/052.png\n",
      "./gen-imgs/053.png\n",
      "./gen-imgs/054.png\n",
      "./gen-imgs/055.png\n",
      "./gen-imgs/056.png\n",
      "./gen-imgs/057.png\n",
      "./gen-imgs/058.png\n",
      "./gen-imgs/059.png\n",
      "./gen-imgs/006.png\n",
      "./gen-imgs/060.png\n",
      "./gen-imgs/061.png\n",
      "./gen-imgs/062.png\n",
      "./gen-imgs/063.png\n",
      "./gen-imgs/064.png\n",
      "./gen-imgs/065.png\n",
      "./gen-imgs/066.png\n",
      "./gen-imgs/067.png\n",
      "./gen-imgs/068.png\n",
      "./gen-imgs/069.png\n",
      "./gen-imgs/007.png\n",
      "./gen-imgs/070.png\n",
      "./gen-imgs/071.png\n",
      "./gen-imgs/072.png\n",
      "./gen-imgs/073.png\n",
      "./gen-imgs/074.png\n",
      "./gen-imgs/075.png\n",
      "./gen-imgs/076.png\n",
      "./gen-imgs/077.png\n",
      "./gen-imgs/078.png\n",
      "./gen-imgs/079.png\n",
      "./gen-imgs/008.png\n",
      "./gen-imgs/080.png\n",
      "./gen-imgs/081.png\n",
      "./gen-imgs/082.png\n",
      "./gen-imgs/083.png\n",
      "./gen-imgs/084.png\n",
      "./gen-imgs/085.png\n",
      "./gen-imgs/086.png\n",
      "./gen-imgs/087.png\n",
      "./gen-imgs/088.png\n",
      "./gen-imgs/089.png\n",
      "./gen-imgs/009.png\n",
      "./gen-imgs/090.png\n",
      "./gen-imgs/091.png\n",
      "./gen-imgs/092.png\n",
      "./gen-imgs/093.png\n",
      "./gen-imgs/094.png\n",
      "./gen-imgs/095.png\n",
      "./gen-imgs/096.png\n",
      "./gen-imgs/097.png\n",
      "./gen-imgs/098.png\n",
      "./gen-imgs/099.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for image_name in image_fns:\n",
    "    split_name = image_name.split('/')\n",
    "    filename = split_name[-1]\n",
    "    path = \"/\".join(split_name[0:2])\n",
    "    \n",
    "    split_filename = filename.split('_')[-1]\n",
    "    corrected_filename = split_filename.rjust(7, '0')\n",
    "    full_path = \"/\".join([path, corrected_filename])\n",
    "    print(full_path)\n",
    "    os.rename(image_name, full_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(glob.glob(\"./gen-imgs/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for filename in filenames:\n",
    "    images.append(imageio.imread(filename))\n",
    "imageio.mimsave('./gen-imgs/first_attempt.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
